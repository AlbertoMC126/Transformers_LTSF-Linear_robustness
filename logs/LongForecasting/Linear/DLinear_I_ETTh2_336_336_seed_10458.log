Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, individual=True, is_training=1, itr=1, label_len=48, learning_rate=0.005, loss='mse', lradj='type1', model='DLinear', model_id='ETTh2_336_336', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=5, pred_len=336, root_path='./dataset/', save_pred_values=False, seed=10458, seq_len=336, target='OT', test_flop=False, train_epochs=20, train_only=False, use_amp=False, use_gpu=False, use_multi_gpu=False)
Use CPU
>>>>>>>start training : ETTh2_336_336_DLinear_ETTh2_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed10458>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
Total number of trainable parameters: 1585248
Total number of parameters: 1585248
	iters: 100, epoch: 1 | loss: 0.6453579
	speed: 0.0276s/iter; left time: 134.5068s
	iters: 200, epoch: 1 | loss: 0.5144862
	speed: 0.0277s/iter; left time: 132.2438s
Epoch: 1 cost time: 6.945005416870117
Epoch: 1, Steps: 249 | Train Loss: 0.6858005 Vali Loss: 0.5763553 Test Loss: 0.9626640
Validation loss decreased (inf --> 0.576355).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5572748
	speed: 0.0535s/iter; left time: 247.7951s
	iters: 200, epoch: 2 | loss: 0.6440138
	speed: 0.0306s/iter; left time: 138.6466s
Epoch: 2 cost time: 7.313608407974243
Epoch: 2, Steps: 249 | Train Loss: 0.6633785 Vali Loss: 0.5078260 Test Loss: 0.7851149
Validation loss decreased (0.576355 --> 0.507826).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4631212
	speed: 0.0568s/iter; left time: 249.0617s
	iters: 200, epoch: 3 | loss: 1.0193307
	speed: 0.0315s/iter; left time: 134.7529s
Epoch: 3 cost time: 7.4064483642578125
Epoch: 3, Steps: 249 | Train Loss: 0.5841189 Vali Loss: 0.4932902 Test Loss: 0.7194039
Validation loss decreased (0.507826 --> 0.493290).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4204183
	speed: 0.0556s/iter; left time: 229.8286s
	iters: 200, epoch: 4 | loss: 0.4320936
	speed: 0.0293s/iter; left time: 118.2738s
Epoch: 4 cost time: 7.196164608001709
Epoch: 4, Steps: 249 | Train Loss: 0.5464008 Vali Loss: 0.5257875 Test Loss: 0.8395036
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.3827920
	speed: 0.0513s/iter; left time: 199.4942s
	iters: 200, epoch: 5 | loss: 0.4386786
	speed: 0.0297s/iter; left time: 112.5736s
Epoch: 5 cost time: 7.260204792022705
Epoch: 5, Steps: 249 | Train Loss: 0.5297745 Vali Loss: 0.4796012 Test Loss: 0.6805891
Validation loss decreased (0.493290 --> 0.479601).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4720665
	speed: 0.0553s/iter; left time: 200.9826s
	iters: 200, epoch: 6 | loss: 0.6712910
	speed: 0.0292s/iter; left time: 103.0829s
Epoch: 6 cost time: 7.217884302139282
Epoch: 6, Steps: 249 | Train Loss: 0.5205896 Vali Loss: 0.4760412 Test Loss: 0.7393709
Validation loss decreased (0.479601 --> 0.476041).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.6709653
	speed: 0.0554s/iter; left time: 187.7155s
	iters: 200, epoch: 7 | loss: 0.4908739
	speed: 0.0305s/iter; left time: 100.1583s
Epoch: 7 cost time: 7.319607496261597
Epoch: 7, Steps: 249 | Train Loss: 0.5168754 Vali Loss: 0.4989480 Test Loss: 0.7775385
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.3668178
	speed: 0.0510s/iter; left time: 160.0675s
	iters: 200, epoch: 8 | loss: 0.3336301
	speed: 0.0268s/iter; left time: 81.5053s
Epoch: 8 cost time: 6.6091203689575195
Epoch: 8, Steps: 249 | Train Loss: 0.5140257 Vali Loss: 0.4818542 Test Loss: 0.7339305
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5837464
	speed: 0.0478s/iter; left time: 138.0102s
	iters: 200, epoch: 9 | loss: 0.5393445
	speed: 0.0272s/iter; left time: 75.7443s
Epoch: 9 cost time: 6.556716680526733
Epoch: 9, Steps: 249 | Train Loss: 0.5127073 Vali Loss: 0.4827551 Test Loss: 0.7165896
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5614303
	speed: 0.0488s/iter; left time: 128.7641s
	iters: 200, epoch: 10 | loss: 0.7596307
	speed: 0.0266s/iter; left time: 67.6343s
Epoch: 10 cost time: 6.492584466934204
Epoch: 10, Steps: 249 | Train Loss: 0.5118470 Vali Loss: 0.4808590 Test Loss: 0.7000077
EarlyStopping counter: 4 out of 5
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.3608877
	speed: 0.0435s/iter; left time: 103.9016s
	iters: 200, epoch: 11 | loss: 0.5795709
	speed: 0.0178s/iter; left time: 40.8777s
Epoch: 11 cost time: 4.6523659229278564
Epoch: 11, Steps: 249 | Train Loss: 0.5115467 Vali Loss: 0.4825221 Test Loss: 0.7130634
EarlyStopping counter: 5 out of 5
Early stopping
Total training time: 86.8274 seconds
>>>>>>>testing : ETTh2_336_336_DLinear_ETTh2_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed10458<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.7373857498168945, mae:0.57138592004776
