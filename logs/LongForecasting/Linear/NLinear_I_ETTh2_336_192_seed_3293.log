Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, individual=True, is_training=1, itr=1, label_len=48, learning_rate=0.005, loss='mse', lradj='type1', model='NLinear', model_id='ETTh2_336_192', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=5, pred_len=192, root_path='./dataset/', save_pred_values=False, seed=3293, seq_len=336, target='OT', test_flop=False, train_epochs=20, train_only=False, use_amp=False, use_gpu=False, use_multi_gpu=False)
Use CPU
>>>>>>>start training : ETTh2_336_192_NLinear_ETTh2_ftM_sl336_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed3293>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
Total number of trainable parameters: 452928
Total number of parameters: 452928
	iters: 100, epoch: 1 | loss: 0.5502146
	speed: 0.0116s/iter; left time: 57.6641s
	iters: 200, epoch: 1 | loss: 1.0881239
	speed: 0.0098s/iter; left time: 47.4941s
Epoch: 1 cost time: 2.6978812217712402
Epoch: 1, Steps: 253 | Train Loss: 0.6413243 Vali Loss: 0.3888443 Test Loss: 0.4624918
Validation loss decreased (inf --> 0.388844).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4243438
	speed: 0.0214s/iter; left time: 100.8475s
	iters: 200, epoch: 2 | loss: 0.7188968
	speed: 0.0100s/iter; left time: 45.9329s
Epoch: 2 cost time: 2.4622514247894287
Epoch: 2, Steps: 253 | Train Loss: 0.6000829 Vali Loss: 0.4669978 Test Loss: 0.4831256
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3906355
	speed: 0.0197s/iter; left time: 87.8539s
	iters: 200, epoch: 3 | loss: 0.6970184
	speed: 0.0098s/iter; left time: 42.5478s
Epoch: 3 cost time: 2.432115316390991
Epoch: 3, Steps: 253 | Train Loss: 0.5182678 Vali Loss: 0.3155800 Test Loss: 0.3740722
Validation loss decreased (0.388844 --> 0.315580).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4589853
	speed: 0.0212s/iter; left time: 89.2636s
	iters: 200, epoch: 4 | loss: 0.4801893
	speed: 0.0097s/iter; left time: 39.9894s
Epoch: 4 cost time: 2.4493205547332764
Epoch: 4, Steps: 253 | Train Loss: 0.4865405 Vali Loss: 0.3086300 Test Loss: 0.3583188
Validation loss decreased (0.315580 --> 0.308630).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.3049453
	speed: 0.0215s/iter; left time: 84.8207s
	iters: 200, epoch: 5 | loss: 0.3996854
	speed: 0.0097s/iter; left time: 37.2672s
Epoch: 5 cost time: 2.4960074424743652
Epoch: 5, Steps: 253 | Train Loss: 0.4751924 Vali Loss: 0.3145793 Test Loss: 0.3507433
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2795385
	speed: 0.0193s/iter; left time: 71.3273s
	iters: 200, epoch: 6 | loss: 0.2814428
	speed: 0.0092s/iter; left time: 33.0636s
Epoch: 6 cost time: 2.3423476219177246
Epoch: 6, Steps: 253 | Train Loss: 0.4687636 Vali Loss: 0.3033863 Test Loss: 0.3503758
Validation loss decreased (0.308630 --> 0.303386).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2821534
	speed: 0.0202s/iter; left time: 69.7195s
	iters: 200, epoch: 7 | loss: 0.5839115
	speed: 0.0096s/iter; left time: 32.0193s
Epoch: 7 cost time: 2.3756301403045654
Epoch: 7, Steps: 253 | Train Loss: 0.4659173 Vali Loss: 0.3024678 Test Loss: 0.3471635
Validation loss decreased (0.303386 --> 0.302468).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.6472436
	speed: 0.0209s/iter; left time: 66.7855s
	iters: 200, epoch: 8 | loss: 0.7268065
	speed: 0.0098s/iter; left time: 30.2873s
Epoch: 8 cost time: 2.4708895683288574
Epoch: 8, Steps: 253 | Train Loss: 0.4634604 Vali Loss: 0.3021634 Test Loss: 0.3488026
Validation loss decreased (0.302468 --> 0.302163).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.3108233
	speed: 0.0210s/iter; left time: 61.6862s
	iters: 200, epoch: 9 | loss: 0.3003561
	speed: 0.0100s/iter; left time: 28.2433s
Epoch: 9 cost time: 2.4510741233825684
Epoch: 9, Steps: 253 | Train Loss: 0.4632563 Vali Loss: 0.3043378 Test Loss: 0.3452614
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2928770
	speed: 0.0188s/iter; left time: 50.4119s
	iters: 200, epoch: 10 | loss: 0.6269749
	speed: 0.0093s/iter; left time: 23.9279s
Epoch: 10 cost time: 2.2498586177825928
Epoch: 10, Steps: 253 | Train Loss: 0.4618121 Vali Loss: 0.3067957 Test Loss: 0.3458676
EarlyStopping counter: 2 out of 5
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5658011
	speed: 0.0154s/iter; left time: 37.5581s
	iters: 200, epoch: 11 | loss: 0.5834669
	speed: 0.0069s/iter; left time: 16.1893s
Epoch: 11 cost time: 1.6513831615447998
Epoch: 11, Steps: 253 | Train Loss: 0.4623148 Vali Loss: 0.3030979 Test Loss: 0.3458158
EarlyStopping counter: 3 out of 5
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5576972
	speed: 0.0115s/iter; left time: 25.1362s
	iters: 200, epoch: 12 | loss: 0.4512984
	speed: 0.0052s/iter; left time: 10.7597s
Epoch: 12 cost time: 1.3414433002471924
Epoch: 12, Steps: 253 | Train Loss: 0.4614961 Vali Loss: 0.3033451 Test Loss: 0.3458757
EarlyStopping counter: 4 out of 5
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4820293
	speed: 0.0115s/iter; left time: 22.2049s
	iters: 200, epoch: 13 | loss: 0.4627073
	speed: 0.0054s/iter; left time: 9.7845s
Epoch: 13 cost time: 1.368422031402588
Epoch: 13, Steps: 253 | Train Loss: 0.4607279 Vali Loss: 0.3034887 Test Loss: 0.3457415
EarlyStopping counter: 5 out of 5
Early stopping
Total training time: 35.4493 seconds
>>>>>>>testing : ETTh2_336_192_NLinear_ETTh2_ftM_sl336_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed3293<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3449114263057709, mae:0.3878324329853058
