Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, individual=True, is_training=1, itr=1, label_len=48, learning_rate=0.05, loss='mse', lradj='type1', model='DLinear', model_id='ETTh2_336_192', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=5, pred_len=192, root_path='./dataset/', save_pred_values=False, seed=15227, seq_len=336, target='OT', test_flop=False, train_epochs=20, train_only=False, use_amp=False, use_gpu=False, use_multi_gpu=False)
Use CPU
>>>>>>>start training : ETTh2_336_192_DLinear_ETTh2_ftM_sl336_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed15227>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
Total number of trainable parameters: 905856
Total number of parameters: 905856
	iters: 100, epoch: 1 | loss: 2.3896084
	speed: 0.0178s/iter; left time: 88.5131s
	iters: 200, epoch: 1 | loss: 2.7157757
	speed: 0.0180s/iter; left time: 87.4078s
Epoch: 1 cost time: 4.494487762451172
Epoch: 1, Steps: 253 | Train Loss: 4.6588741 Vali Loss: 2.5224445 Test Loss: 5.0918994
Validation loss decreased (inf --> 2.522444).  Saving model ...
Updating learning rate to 0.05
	iters: 100, epoch: 2 | loss: 3.1008697
	speed: 0.0366s/iter; left time: 172.5192s
	iters: 200, epoch: 2 | loss: 2.0967736
	speed: 0.0183s/iter; left time: 84.1602s
Epoch: 2 cost time: 4.6854612827301025
Epoch: 2, Steps: 253 | Train Loss: 3.8708614 Vali Loss: 6.0303402 Test Loss: 23.9003181
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.025
	iters: 100, epoch: 3 | loss: 0.9814975
	speed: 0.0366s/iter; left time: 162.8424s
	iters: 200, epoch: 3 | loss: 0.6372908
	speed: 0.0183s/iter; left time: 79.6828s
Epoch: 3 cost time: 4.50559139251709
Epoch: 3, Steps: 253 | Train Loss: 1.0123949 Vali Loss: 0.8158578 Test Loss: 1.5169983
Validation loss decreased (2.522444 --> 0.815858).  Saving model ...
Updating learning rate to 0.0125
	iters: 100, epoch: 4 | loss: 0.5927027
	speed: 0.0355s/iter; left time: 149.2007s
	iters: 200, epoch: 4 | loss: 0.4191923
	speed: 0.0174s/iter; left time: 71.2511s
Epoch: 4 cost time: 4.338149785995483
Epoch: 4, Steps: 253 | Train Loss: 0.5992149 Vali Loss: 0.4357677 Test Loss: 0.7385859
Validation loss decreased (0.815858 --> 0.435768).  Saving model ...
Updating learning rate to 0.00625
	iters: 100, epoch: 5 | loss: 0.4842440
	speed: 0.0389s/iter; left time: 153.7928s
	iters: 200, epoch: 5 | loss: 0.5340444
	speed: 0.0211s/iter; left time: 81.2879s
Epoch: 5 cost time: 4.979756116867065
Epoch: 5, Steps: 253 | Train Loss: 0.5117115 Vali Loss: 0.4601878 Test Loss: 0.7451167
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.003125
	iters: 100, epoch: 6 | loss: 0.4655525
	speed: 0.0333s/iter; left time: 123.1128s
	iters: 200, epoch: 6 | loss: 0.5330681
	speed: 0.0175s/iter; left time: 63.0467s
Epoch: 6 cost time: 4.289312124252319
Epoch: 6, Steps: 253 | Train Loss: 0.4772263 Vali Loss: 0.4016579 Test Loss: 0.6203977
Validation loss decreased (0.435768 --> 0.401658).  Saving model ...
Updating learning rate to 0.0015625
	iters: 100, epoch: 7 | loss: 0.5596843
	speed: 0.0353s/iter; left time: 121.6868s
	iters: 200, epoch: 7 | loss: 0.2050864
	speed: 0.0173s/iter; left time: 57.9909s
Epoch: 7 cost time: 4.245714902877808
Epoch: 7, Steps: 253 | Train Loss: 0.4578839 Vali Loss: 0.3722878 Test Loss: 0.5567004
Validation loss decreased (0.401658 --> 0.372288).  Saving model ...
Updating learning rate to 0.00078125
	iters: 100, epoch: 8 | loss: 0.3797326
	speed: 0.0349s/iter; left time: 111.2069s
	iters: 200, epoch: 8 | loss: 0.4046835
	speed: 0.0177s/iter; left time: 54.5703s
Epoch: 8 cost time: 4.230694770812988
Epoch: 8, Steps: 253 | Train Loss: 0.4471042 Vali Loss: 0.3643359 Test Loss: 0.5440379
Validation loss decreased (0.372288 --> 0.364336).  Saving model ...
Updating learning rate to 0.000390625
	iters: 100, epoch: 9 | loss: 0.2329949
	speed: 0.0346s/iter; left time: 101.6769s
	iters: 200, epoch: 9 | loss: 0.2618680
	speed: 0.0175s/iter; left time: 49.5326s
Epoch: 9 cost time: 4.295909881591797
Epoch: 9, Steps: 253 | Train Loss: 0.4416937 Vali Loss: 0.3659303 Test Loss: 0.4992293
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001953125
	iters: 100, epoch: 10 | loss: 0.2853181
	speed: 0.0327s/iter; left time: 87.7450s
	iters: 200, epoch: 10 | loss: 0.3884465
	speed: 0.0174s/iter; left time: 45.0422s
Epoch: 10 cost time: 4.252960205078125
Epoch: 10, Steps: 253 | Train Loss: 0.4386434 Vali Loss: 0.3811727 Test Loss: 0.5801401
EarlyStopping counter: 2 out of 5
Updating learning rate to 9.765625e-05
	iters: 100, epoch: 11 | loss: 0.3552400
	speed: 0.0342s/iter; left time: 83.1440s
	iters: 200, epoch: 11 | loss: 0.4844829
	speed: 0.0176s/iter; left time: 40.9822s
Epoch: 11 cost time: 4.33347487449646
Epoch: 11, Steps: 253 | Train Loss: 0.4374272 Vali Loss: 0.3771291 Test Loss: 0.5710520
EarlyStopping counter: 3 out of 5
Updating learning rate to 4.8828125e-05
	iters: 100, epoch: 12 | loss: 0.3068872
	speed: 0.0329s/iter; left time: 71.5741s
	iters: 200, epoch: 12 | loss: 0.5673067
	speed: 0.0159s/iter; left time: 32.9468s
Epoch: 12 cost time: 3.8258113861083984
Epoch: 12, Steps: 253 | Train Loss: 0.4365009 Vali Loss: 0.3849361 Test Loss: 0.5936815
EarlyStopping counter: 4 out of 5
Updating learning rate to 2.44140625e-05
	iters: 100, epoch: 13 | loss: 0.2776731
	speed: 0.0258s/iter; left time: 49.6518s
	iters: 200, epoch: 13 | loss: 0.6486257
	speed: 0.0120s/iter; left time: 21.9125s
Epoch: 13 cost time: 2.968264579772949
Epoch: 13, Steps: 253 | Train Loss: 0.4357835 Vali Loss: 0.3775644 Test Loss: 0.5709369
EarlyStopping counter: 5 out of 5
Early stopping
Total training time: 66.7631 seconds
>>>>>>>testing : ETTh2_336_192_DLinear_ETTh2_ftM_sl336_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed15227<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.5460893511772156, mae:0.48732486367225647
