Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, individual=True, is_training=1, itr=1, label_len=48, learning_rate=0.05, loss='mse', lradj='type1', model='DLinear', model_id='ETTh2_336_192', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=5, pred_len=192, root_path='./dataset/', save_pred_values=False, seed=15726, seq_len=336, target='OT', test_flop=False, train_epochs=20, train_only=False, use_amp=False, use_gpu=False, use_multi_gpu=False)
Use CPU
>>>>>>>start training : ETTh2_336_192_DLinear_ETTh2_ftM_sl336_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed15726>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
Total number of trainable parameters: 905856
Total number of parameters: 905856
	iters: 100, epoch: 1 | loss: 1.5752150
	speed: 0.0179s/iter; left time: 88.9585s
	iters: 200, epoch: 1 | loss: 2.7291958
	speed: 0.0182s/iter; left time: 88.6010s
Epoch: 1 cost time: 4.552743434906006
Epoch: 1, Steps: 253 | Train Loss: 3.8651175 Vali Loss: 2.7965052 Test Loss: 7.2530074
Validation loss decreased (inf --> 2.796505).  Saving model ...
Updating learning rate to 0.05
	iters: 100, epoch: 2 | loss: 4.7709966
	speed: 0.0368s/iter; left time: 173.1932s
	iters: 200, epoch: 2 | loss: 4.9409509
	speed: 0.0182s/iter; left time: 83.9851s
Epoch: 2 cost time: 4.710812330245972
Epoch: 2, Steps: 253 | Train Loss: 5.0578503 Vali Loss: 2.8013582 Test Loss: 4.7496796
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.025
	iters: 100, epoch: 3 | loss: 0.7194085
	speed: 0.0379s/iter; left time: 169.0143s
	iters: 200, epoch: 3 | loss: 0.6234476
	speed: 0.0190s/iter; left time: 82.9306s
Epoch: 3 cost time: 4.620245456695557
Epoch: 3, Steps: 253 | Train Loss: 1.1093553 Vali Loss: 0.8858839 Test Loss: 2.3377447
Validation loss decreased (2.796505 --> 0.885884).  Saving model ...
Updating learning rate to 0.0125
	iters: 100, epoch: 4 | loss: 0.3521248
	speed: 0.0363s/iter; left time: 152.7087s
	iters: 200, epoch: 4 | loss: 0.9296145
	speed: 0.0179s/iter; left time: 73.5297s
Epoch: 4 cost time: 4.362013816833496
Epoch: 4, Steps: 253 | Train Loss: 0.5978106 Vali Loss: 0.4556722 Test Loss: 0.7315030
Validation loss decreased (0.885884 --> 0.455672).  Saving model ...
Updating learning rate to 0.00625
	iters: 100, epoch: 5 | loss: 0.6122859
	speed: 0.0393s/iter; left time: 155.3068s
	iters: 200, epoch: 5 | loss: 0.5740556
	speed: 0.0213s/iter; left time: 81.9708s
Epoch: 5 cost time: 4.972733974456787
Epoch: 5, Steps: 253 | Train Loss: 0.5143132 Vali Loss: 0.3970406 Test Loss: 0.5077655
Validation loss decreased (0.455672 --> 0.397041).  Saving model ...
Updating learning rate to 0.003125
	iters: 100, epoch: 6 | loss: 0.4331829
	speed: 0.0358s/iter; left time: 132.3669s
	iters: 200, epoch: 6 | loss: 0.5812500
	speed: 0.0175s/iter; left time: 62.7921s
Epoch: 6 cost time: 4.356958389282227
Epoch: 6, Steps: 253 | Train Loss: 0.4802153 Vali Loss: 0.3800015 Test Loss: 0.5161633
Validation loss decreased (0.397041 --> 0.380002).  Saving model ...
Updating learning rate to 0.0015625
	iters: 100, epoch: 7 | loss: 0.5880148
	speed: 0.0359s/iter; left time: 123.4486s
	iters: 200, epoch: 7 | loss: 0.5612891
	speed: 0.0172s/iter; left time: 57.5822s
Epoch: 7 cost time: 4.351708173751831
Epoch: 7, Steps: 253 | Train Loss: 0.4599574 Vali Loss: 0.3980037 Test Loss: 0.6224988
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00078125
	iters: 100, epoch: 8 | loss: 0.3973300
	speed: 0.0345s/iter; left time: 110.0782s
	iters: 200, epoch: 8 | loss: 0.5316318
	speed: 0.0177s/iter; left time: 54.6032s
Epoch: 8 cost time: 4.328377723693848
Epoch: 8, Steps: 253 | Train Loss: 0.4511071 Vali Loss: 0.4180881 Test Loss: 0.7233901
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.000390625
	iters: 100, epoch: 9 | loss: 0.5924096
	speed: 0.0328s/iter; left time: 96.4485s
	iters: 200, epoch: 9 | loss: 0.3656374
	speed: 0.0177s/iter; left time: 50.1149s
Epoch: 9 cost time: 4.3199303150177
Epoch: 9, Steps: 253 | Train Loss: 0.4449462 Vali Loss: 0.4101913 Test Loss: 0.6973792
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0001953125
	iters: 100, epoch: 10 | loss: 0.3128345
	speed: 0.0345s/iter; left time: 92.6193s
	iters: 200, epoch: 10 | loss: 0.7347142
	speed: 0.0178s/iter; left time: 45.9761s
Epoch: 10 cost time: 4.334769248962402
Epoch: 10, Steps: 253 | Train Loss: 0.4427895 Vali Loss: 0.3877615 Test Loss: 0.6029493
EarlyStopping counter: 4 out of 5
Updating learning rate to 9.765625e-05
	iters: 100, epoch: 11 | loss: 0.3340475
	speed: 0.0346s/iter; left time: 84.0108s
	iters: 200, epoch: 11 | loss: 0.6384416
	speed: 0.0178s/iter; left time: 41.5686s
Epoch: 11 cost time: 4.388776540756226
Epoch: 11, Steps: 253 | Train Loss: 0.4407789 Vali Loss: 0.3920629 Test Loss: 0.6273572
EarlyStopping counter: 5 out of 5
Early stopping
Total training time: 59.3817 seconds
>>>>>>>testing : ETTh2_336_192_DLinear_ETTh2_ftM_sl336_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed15726<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.5171199440956116, mae:0.49554443359375
