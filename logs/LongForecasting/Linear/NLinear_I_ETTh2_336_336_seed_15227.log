Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, individual=True, is_training=1, itr=1, label_len=48, learning_rate=0.005, loss='mse', lradj='type1', model='NLinear', model_id='ETTh2_336_336', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=5, pred_len=336, root_path='./dataset/', save_pred_values=False, seed=15227, seq_len=336, target='OT', test_flop=False, train_epochs=20, train_only=False, use_amp=False, use_gpu=False, use_multi_gpu=False)
Use CPU
>>>>>>>start training : ETTh2_336_336_NLinear_ETTh2_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed15227>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
Total number of trainable parameters: 792624
Total number of parameters: 792624
	iters: 100, epoch: 1 | loss: 0.6616272
	speed: 0.0157s/iter; left time: 76.6355s
	iters: 200, epoch: 1 | loss: 0.8116658
	speed: 0.0159s/iter; left time: 75.8026s
Epoch: 1 cost time: 3.955610513687134
Epoch: 1, Steps: 249 | Train Loss: 0.7231394 Vali Loss: 0.4623296 Test Loss: 0.4475482
Validation loss decreased (inf --> 0.462330).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4375907
	speed: 0.0325s/iter; left time: 150.6510s
	iters: 200, epoch: 2 | loss: 0.4865822
	speed: 0.0171s/iter; left time: 77.4214s
Epoch: 2 cost time: 4.1760478019714355
Epoch: 2, Steps: 249 | Train Loss: 0.7043578 Vali Loss: 0.4334176 Test Loss: 0.4204410
Validation loss decreased (0.462330 --> 0.433418).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5187061
	speed: 0.0334s/iter; left time: 146.5629s
	iters: 200, epoch: 3 | loss: 0.4264690
	speed: 0.0179s/iter; left time: 76.7593s
Epoch: 3 cost time: 4.363286256790161
Epoch: 3, Steps: 249 | Train Loss: 0.6099343 Vali Loss: 0.4192562 Test Loss: 0.4090704
Validation loss decreased (0.433418 --> 0.419256).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.7516724
	speed: 0.0340s/iter; left time: 140.7584s
	iters: 200, epoch: 4 | loss: 0.8520300
	speed: 0.0175s/iter; left time: 70.7694s
Epoch: 4 cost time: 4.300784111022949
Epoch: 4, Steps: 249 | Train Loss: 0.5900695 Vali Loss: 0.4171031 Test Loss: 0.3808296
Validation loss decreased (0.419256 --> 0.417103).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4844183
	speed: 0.0335s/iter; left time: 129.9736s
	iters: 200, epoch: 5 | loss: 0.5929157
	speed: 0.0169s/iter; left time: 64.1441s
Epoch: 5 cost time: 4.162115573883057
Epoch: 5, Steps: 249 | Train Loss: 0.5707252 Vali Loss: 0.3942379 Test Loss: 0.3795833
Validation loss decreased (0.417103 --> 0.394238).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.6734791
	speed: 0.0322s/iter; left time: 116.9093s
	iters: 200, epoch: 6 | loss: 1.2440735
	speed: 0.0168s/iter; left time: 59.2386s
Epoch: 6 cost time: 4.060328960418701
Epoch: 6, Steps: 249 | Train Loss: 0.5654423 Vali Loss: 0.3958169 Test Loss: 0.3751091
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.3890111
	speed: 0.0309s/iter; left time: 104.6776s
	iters: 200, epoch: 7 | loss: 0.6496022
	speed: 0.0168s/iter; left time: 55.1245s
Epoch: 7 cost time: 4.070446968078613
Epoch: 7, Steps: 249 | Train Loss: 0.5626376 Vali Loss: 0.3982796 Test Loss: 0.3742398
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.7524062
	speed: 0.0316s/iter; left time: 99.0944s
	iters: 200, epoch: 8 | loss: 0.3972591
	speed: 0.0175s/iter; left time: 53.1955s
Epoch: 8 cost time: 4.20233416557312
Epoch: 8, Steps: 249 | Train Loss: 0.5608594 Vali Loss: 0.3936552 Test Loss: 0.3742372
Validation loss decreased (0.394238 --> 0.393655).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4038644
	speed: 0.0345s/iter; left time: 99.7116s
	iters: 200, epoch: 9 | loss: 0.6163921
	speed: 0.0173s/iter; left time: 48.2841s
Epoch: 9 cost time: 4.300012111663818
Epoch: 9, Steps: 249 | Train Loss: 0.5599508 Vali Loss: 0.3944137 Test Loss: 0.3737982
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4564841
	speed: 0.0309s/iter; left time: 81.6428s
	iters: 200, epoch: 10 | loss: 0.6206506
	speed: 0.0143s/iter; left time: 36.2209s
Epoch: 10 cost time: 3.616063356399536
Epoch: 10, Steps: 249 | Train Loss: 0.5593230 Vali Loss: 0.3945584 Test Loss: 0.3742250
EarlyStopping counter: 2 out of 5
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5369461
	speed: 0.0240s/iter; left time: 57.3098s
	iters: 200, epoch: 11 | loss: 0.6218284
	speed: 0.0124s/iter; left time: 28.4746s
Epoch: 11 cost time: 3.0504326820373535
Epoch: 11, Steps: 249 | Train Loss: 0.5589916 Vali Loss: 0.3951125 Test Loss: 0.3733632
EarlyStopping counter: 3 out of 5
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4460464
	speed: 0.0218s/iter; left time: 46.6282s
	iters: 200, epoch: 12 | loss: 0.7017781
	speed: 0.0113s/iter; left time: 22.9770s
Epoch: 12 cost time: 2.6541144847869873
Epoch: 12, Steps: 249 | Train Loss: 0.5589551 Vali Loss: 0.3943422 Test Loss: 0.3735525
EarlyStopping counter: 4 out of 5
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4905281
	speed: 0.0197s/iter; left time: 37.2881s
	iters: 200, epoch: 13 | loss: 0.3684126
	speed: 0.0104s/iter; left time: 18.6672s
Epoch: 13 cost time: 2.518517255783081
Epoch: 13, Steps: 249 | Train Loss: 0.5588347 Vali Loss: 0.3953548 Test Loss: 0.3736768
EarlyStopping counter: 5 out of 5
Early stopping
Total training time: 58.6226 seconds
>>>>>>>testing : ETTh2_336_336_NLinear_ETTh2_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed15227<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.36986225843429565, mae:0.41201239824295044
