Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, individual=True, is_training=1, itr=1, label_len=48, learning_rate=0.005, loss='mse', lradj='type1', model='NLinear', model_id='ETTh2_336_336', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=5, pred_len=336, root_path='./dataset/', save_pred_values=False, seed=3144, seq_len=336, target='OT', test_flop=False, train_epochs=20, train_only=False, use_amp=False, use_gpu=False, use_multi_gpu=False)
Use CPU
>>>>>>>start training : ETTh2_336_336_NLinear_ETTh2_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed3144>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
Total number of trainable parameters: 792624
Total number of parameters: 792624
	iters: 100, epoch: 1 | loss: 0.4719883
	speed: 0.0159s/iter; left time: 77.8453s
	iters: 200, epoch: 1 | loss: 0.8080776
	speed: 0.0158s/iter; left time: 75.6671s
Epoch: 1 cost time: 3.9289960861206055
Epoch: 1, Steps: 249 | Train Loss: 0.7245280 Vali Loss: 0.5219639 Test Loss: 0.4902694
Validation loss decreased (inf --> 0.521964).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.7350732
	speed: 0.0331s/iter; left time: 153.1266s
	iters: 200, epoch: 2 | loss: 0.8701754
	speed: 0.0170s/iter; left time: 76.8759s
Epoch: 2 cost time: 4.170461893081665
Epoch: 2, Steps: 249 | Train Loss: 0.6818214 Vali Loss: 0.4286360 Test Loss: 0.4343655
Validation loss decreased (0.521964 --> 0.428636).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4453851
	speed: 0.0328s/iter; left time: 143.9163s
	iters: 200, epoch: 3 | loss: 0.3679761
	speed: 0.0177s/iter; left time: 75.8886s
Epoch: 3 cost time: 4.340475797653198
Epoch: 3, Steps: 249 | Train Loss: 0.6178756 Vali Loss: 0.4061229 Test Loss: 0.3962486
Validation loss decreased (0.428636 --> 0.406123).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.7491241
	speed: 0.0358s/iter; left time: 147.9787s
	iters: 200, epoch: 4 | loss: 0.3895269
	speed: 0.0173s/iter; left time: 69.8368s
Epoch: 4 cost time: 4.196501970291138
Epoch: 4, Steps: 249 | Train Loss: 0.5857248 Vali Loss: 0.4024300 Test Loss: 0.3954943
Validation loss decreased (0.406123 --> 0.402430).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4566779
	speed: 0.0344s/iter; left time: 133.5343s
	iters: 200, epoch: 5 | loss: 0.8241364
	speed: 0.0168s/iter; left time: 63.6257s
Epoch: 5 cost time: 4.0956621170043945
Epoch: 5, Steps: 249 | Train Loss: 0.5756437 Vali Loss: 0.4138559 Test Loss: 0.3754104
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.3557011
	speed: 0.0313s/iter; left time: 113.7334s
	iters: 200, epoch: 6 | loss: 0.4540050
	speed: 0.0165s/iter; left time: 58.4754s
Epoch: 6 cost time: 4.046088218688965
Epoch: 6, Steps: 249 | Train Loss: 0.5661990 Vali Loss: 0.3817157 Test Loss: 0.3869896
Validation loss decreased (0.402430 --> 0.381716).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.7462833
	speed: 0.0329s/iter; left time: 111.4121s
	iters: 200, epoch: 7 | loss: 0.7277398
	speed: 0.0164s/iter; left time: 53.9987s
Epoch: 7 cost time: 3.963991403579712
Epoch: 7, Steps: 249 | Train Loss: 0.5626490 Vali Loss: 0.3895805 Test Loss: 0.3777175
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.7556403
	speed: 0.0316s/iter; left time: 99.0065s
	iters: 200, epoch: 8 | loss: 0.5475723
	speed: 0.0168s/iter; left time: 50.9662s
Epoch: 8 cost time: 4.1137354373931885
Epoch: 8, Steps: 249 | Train Loss: 0.5610111 Vali Loss: 0.3992988 Test Loss: 0.3734267
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5978175
	speed: 0.0325s/iter; left time: 93.7728s
	iters: 200, epoch: 9 | loss: 0.4736303
	speed: 0.0174s/iter; left time: 48.5044s
Epoch: 9 cost time: 4.299569368362427
Epoch: 9, Steps: 249 | Train Loss: 0.5599182 Vali Loss: 0.3974588 Test Loss: 0.3720890
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5078372
	speed: 0.0304s/iter; left time: 80.2378s
	iters: 200, epoch: 10 | loss: 0.4406992
	speed: 0.0139s/iter; left time: 35.3951s
Epoch: 10 cost time: 3.5941715240478516
Epoch: 10, Steps: 249 | Train Loss: 0.5593383 Vali Loss: 0.3942170 Test Loss: 0.3738732
EarlyStopping counter: 4 out of 5
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.3284606
	speed: 0.0238s/iter; left time: 56.8338s
	iters: 200, epoch: 11 | loss: 0.5117780
	speed: 0.0127s/iter; left time: 29.1364s
Epoch: 11 cost time: 3.0355608463287354
Epoch: 11, Steps: 249 | Train Loss: 0.5590454 Vali Loss: 0.3928911 Test Loss: 0.3740311
EarlyStopping counter: 5 out of 5
Early stopping
Total training time: 52.3404 seconds
>>>>>>>testing : ETTh2_336_336_NLinear_ETTh2_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed3144<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.3826196789741516, mae:0.4175470769405365
