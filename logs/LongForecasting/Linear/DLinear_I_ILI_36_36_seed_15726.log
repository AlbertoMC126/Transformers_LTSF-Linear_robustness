Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='national_illness.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, individual=True, is_training=1, itr=1, label_len=18, learning_rate=0.05, loss='mse', lradj='type1', model='DLinear', model_id='national_illness_36_36', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=5, pred_len=36, root_path='./dataset/', save_pred_values=False, seed=15726, seq_len=36, target='OT', test_flop=False, train_epochs=20, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : national_illness_36_36_DLinear_custom_ftM_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed15726>>>>>>>>>>>>>>>>>>>>>>>>>>
train 605
val 62
test 158
Total number of trainable parameters: 18648
Total number of parameters: 18648
Epoch: 1 cost time: 15.14252519607544
Epoch: 1, Steps: 18 | Train Loss: 0.9003023 Vali Loss: 0.4738133 Test Loss: 4.0461378
Validation loss decreased (inf --> 0.473813).  Saving model ...
Updating learning rate to 0.05
Epoch: 2 cost time: 0.6960947513580322
Epoch: 2, Steps: 18 | Train Loss: 0.7115649 Vali Loss: 0.4480812 Test Loss: 3.8142924
Validation loss decreased (0.473813 --> 0.448081).  Saving model ...
Updating learning rate to 0.025
Epoch: 3 cost time: 0.7637848854064941
Epoch: 3, Steps: 18 | Train Loss: 0.6194759 Vali Loss: 0.3867838 Test Loss: 3.1044927
Validation loss decreased (0.448081 --> 0.386784).  Saving model ...
Updating learning rate to 0.0125
Epoch: 4 cost time: 0.7524404525756836
Epoch: 4, Steps: 18 | Train Loss: 0.5815015 Vali Loss: 0.3860614 Test Loss: 2.7636154
Validation loss decreased (0.386784 --> 0.386061).  Saving model ...
Updating learning rate to 0.00625
Epoch: 5 cost time: 0.7450649738311768
Epoch: 5, Steps: 18 | Train Loss: 0.5598529 Vali Loss: 0.3522751 Test Loss: 2.7966046
Validation loss decreased (0.386061 --> 0.352275).  Saving model ...
Updating learning rate to 0.003125
Epoch: 6 cost time: 0.6952991485595703
Epoch: 6, Steps: 18 | Train Loss: 0.5441976 Vali Loss: 0.3553115 Test Loss: 2.7449903
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0015625
Epoch: 7 cost time: 0.7045495510101318
Epoch: 7, Steps: 18 | Train Loss: 0.5248866 Vali Loss: 0.3431618 Test Loss: 2.7569671
Validation loss decreased (0.352275 --> 0.343162).  Saving model ...
Updating learning rate to 0.00078125
Epoch: 8 cost time: 0.6923472881317139
Epoch: 8, Steps: 18 | Train Loss: 0.5449685 Vali Loss: 0.3450302 Test Loss: 2.7460771
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.000390625
Epoch: 9 cost time: 0.6481585502624512
Epoch: 9, Steps: 18 | Train Loss: 0.5366728 Vali Loss: 0.3689953 Test Loss: 2.7447577
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0001953125
Epoch: 10 cost time: 0.5418472290039062
Epoch: 10, Steps: 18 | Train Loss: 0.5319959 Vali Loss: 0.3655976 Test Loss: 2.7477841
EarlyStopping counter: 3 out of 5
Updating learning rate to 9.765625e-05
Epoch: 11 cost time: 0.5159282684326172
Epoch: 11, Steps: 18 | Train Loss: 0.5460953 Vali Loss: 0.3619601 Test Loss: 2.7455094
EarlyStopping counter: 4 out of 5
Updating learning rate to 4.8828125e-05
Epoch: 12 cost time: 0.44557642936706543
Epoch: 12, Steps: 18 | Train Loss: 0.5425081 Vali Loss: 0.3408445 Test Loss: 2.7472949
Validation loss decreased (0.343162 --> 0.340844).  Saving model ...
Updating learning rate to 2.44140625e-05
Epoch: 13 cost time: 0.38590073585510254
Epoch: 13, Steps: 18 | Train Loss: 0.5446302 Vali Loss: 0.3560003 Test Loss: 2.7455719
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.220703125e-05
Epoch: 14 cost time: 0.33166956901550293
Epoch: 14, Steps: 18 | Train Loss: 0.5498995 Vali Loss: 0.3416086 Test Loss: 2.7456350
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.103515625e-06
Epoch: 15 cost time: 0.3145565986633301
Epoch: 15, Steps: 18 | Train Loss: 0.5313012 Vali Loss: 0.3803667 Test Loss: 2.7456832
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.0517578125e-06
Epoch: 16 cost time: 0.288989782333374
Epoch: 16, Steps: 18 | Train Loss: 0.5406145 Vali Loss: 0.3188784 Test Loss: 2.7456512
Validation loss decreased (0.340844 --> 0.318878).  Saving model ...
Updating learning rate to 1.52587890625e-06
Epoch: 17 cost time: 0.2328343391418457
Epoch: 17, Steps: 18 | Train Loss: 0.5353112 Vali Loss: 0.2873047 Test Loss: 2.7456491
Validation loss decreased (0.318878 --> 0.287305).  Saving model ...
Updating learning rate to 7.62939453125e-07
Epoch: 18 cost time: 0.1860506534576416
Epoch: 18, Steps: 18 | Train Loss: 0.5424823 Vali Loss: 0.3610092 Test Loss: 2.7456512
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.814697265625e-07
Epoch: 19 cost time: 0.11133980751037598
Epoch: 19, Steps: 18 | Train Loss: 0.5349554 Vali Loss: 0.3481618 Test Loss: 2.7456508
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.9073486328125e-07
Epoch: 20 cost time: 0.09102678298950195
Epoch: 20, Steps: 18 | Train Loss: 0.5368209 Vali Loss: 0.3117362 Test Loss: 2.7456462
EarlyStopping counter: 3 out of 5
Updating learning rate to 9.5367431640625e-08
Total training time: 26.1140 seconds
>>>>>>>testing : national_illness_36_36_DLinear_custom_ftM_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed15726<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 158
mse:2.7485849857330322, mae:1.0720375776290894
