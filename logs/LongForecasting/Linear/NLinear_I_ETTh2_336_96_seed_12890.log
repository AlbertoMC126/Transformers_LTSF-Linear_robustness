Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, individual=True, is_training=1, itr=1, label_len=48, learning_rate=0.005, loss='mse', lradj='type1', model='NLinear', model_id='ETTh2_336_96', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=5, pred_len=96, root_path='./dataset/', save_pred_values=False, seed=12890, seq_len=336, target='OT', test_flop=False, train_epochs=20, train_only=False, use_amp=False, use_gpu=False, use_multi_gpu=False)
Use CPU
>>>>>>>start training : ETTh2_336_96_NLinear_ETTh2_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed12890>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
Total number of trainable parameters: 226464
Total number of parameters: 226464
	iters: 100, epoch: 1 | loss: 0.4415423
	speed: 0.0056s/iter; left time: 27.9729s
	iters: 200, epoch: 1 | loss: 0.4267463
	speed: 0.0057s/iter; left time: 28.1498s
Epoch: 1 cost time: 1.438415288925171
Epoch: 1, Steps: 256 | Train Loss: 0.5073942 Vali Loss: 0.4069696 Test Loss: 0.4503717
Validation loss decreased (inf --> 0.406970).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6804445
	speed: 0.0123s/iter; left time: 58.5914s
	iters: 200, epoch: 2 | loss: 0.4288093
	speed: 0.0059s/iter; left time: 27.5821s
Epoch: 2 cost time: 1.463926076889038
Epoch: 2, Steps: 256 | Train Loss: 0.5244748 Vali Loss: 0.3244021 Test Loss: 0.4191363
Validation loss decreased (0.406970 --> 0.324402).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.8100458
	speed: 0.0141s/iter; left time: 63.3551s
	iters: 200, epoch: 3 | loss: 0.4945656
	speed: 0.0064s/iter; left time: 28.3053s
Epoch: 3 cost time: 1.565960168838501
Epoch: 3, Steps: 256 | Train Loss: 0.4180848 Vali Loss: 0.2655651 Test Loss: 0.3252933
Validation loss decreased (0.324402 --> 0.265565).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5460634
	speed: 0.0139s/iter; left time: 59.0575s
	iters: 200, epoch: 4 | loss: 0.2489399
	speed: 0.0053s/iter; left time: 22.1580s
Epoch: 4 cost time: 1.4309828281402588
Epoch: 4, Steps: 256 | Train Loss: 0.3854158 Vali Loss: 0.2295415 Test Loss: 0.2957124
Validation loss decreased (0.265565 --> 0.229541).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2418920
	speed: 0.0142s/iter; left time: 56.6701s
	iters: 200, epoch: 5 | loss: 0.4856909
	speed: 0.0061s/iter; left time: 23.6269s
Epoch: 5 cost time: 1.6062650680541992
Epoch: 5, Steps: 256 | Train Loss: 0.3721241 Vali Loss: 0.2375204 Test Loss: 0.2921561
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.3181086
	speed: 0.0135s/iter; left time: 50.6336s
	iters: 200, epoch: 6 | loss: 0.4960517
	speed: 0.0058s/iter; left time: 20.9478s
Epoch: 6 cost time: 1.495492935180664
Epoch: 6, Steps: 256 | Train Loss: 0.3669382 Vali Loss: 0.2225303 Test Loss: 0.2898720
Validation loss decreased (0.229541 --> 0.222530).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2889231
	speed: 0.0131s/iter; left time: 45.7681s
	iters: 200, epoch: 7 | loss: 0.4271069
	speed: 0.0065s/iter; left time: 21.9680s
Epoch: 7 cost time: 1.532855749130249
Epoch: 7, Steps: 256 | Train Loss: 0.3641327 Vali Loss: 0.2337183 Test Loss: 0.2898220
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5987059
	speed: 0.0121s/iter; left time: 39.1236s
	iters: 200, epoch: 8 | loss: 0.2099567
	speed: 0.0057s/iter; left time: 17.9389s
Epoch: 8 cost time: 1.4604055881500244
Epoch: 8, Steps: 256 | Train Loss: 0.3623500 Vali Loss: 0.2289177 Test Loss: 0.2871210
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.3159445
	speed: 0.0142s/iter; left time: 42.0694s
	iters: 200, epoch: 9 | loss: 0.4294772
	speed: 0.0061s/iter; left time: 17.6376s
Epoch: 9 cost time: 1.568329095840454
Epoch: 9, Steps: 256 | Train Loss: 0.3614745 Vali Loss: 0.2268837 Test Loss: 0.2865245
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4119203
	speed: 0.0125s/iter; left time: 34.0055s
	iters: 200, epoch: 10 | loss: 0.3754737
	speed: 0.0063s/iter; left time: 16.5842s
Epoch: 10 cost time: 1.5717988014221191
Epoch: 10, Steps: 256 | Train Loss: 0.3611532 Vali Loss: 0.2255814 Test Loss: 0.2858932
EarlyStopping counter: 4 out of 5
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5065960
	speed: 0.0134s/iter; left time: 32.9686s
	iters: 200, epoch: 11 | loss: 0.3014510
	speed: 0.0056s/iter; left time: 13.2374s
Epoch: 11 cost time: 1.5318117141723633
Epoch: 11, Steps: 256 | Train Loss: 0.3612254 Vali Loss: 0.2266438 Test Loss: 0.2861429
EarlyStopping counter: 5 out of 5
Early stopping
Total training time: 21.1639 seconds
>>>>>>>testing : ETTh2_336_96_NLinear_ETTh2_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed12890<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.29096874594688416, mae:0.3487364947795868
