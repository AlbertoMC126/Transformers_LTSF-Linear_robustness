Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTh2', data_path='ETTh2.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=1, features='M', freq='h', gpu=0, individual=True, is_training=1, itr=1, label_len=48, learning_rate=0.005, loss='mse', lradj='type1', model='NLinear', model_id='ETTh2_336_336', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=5, pred_len=336, root_path='./dataset/', save_pred_values=False, seed=15726, seq_len=336, target='OT', test_flop=False, train_epochs=20, train_only=False, use_amp=False, use_gpu=False, use_multi_gpu=False)
Use CPU
>>>>>>>start training : ETTh2_336_336_NLinear_ETTh2_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed15726>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
Total number of trainable parameters: 792624
Total number of parameters: 792624
	iters: 100, epoch: 1 | loss: 0.6193712
	speed: 0.0156s/iter; left time: 76.3073s
	iters: 200, epoch: 1 | loss: 0.5070851
	speed: 0.0158s/iter; left time: 75.4397s
Epoch: 1 cost time: 3.944331645965576
Epoch: 1, Steps: 249 | Train Loss: 0.7325678 Vali Loss: 0.5312344 Test Loss: 0.6945620
Validation loss decreased (inf --> 0.531234).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.7076234
	speed: 0.0334s/iter; left time: 154.5477s
	iters: 200, epoch: 2 | loss: 0.7741034
	speed: 0.0170s/iter; left time: 76.8577s
Epoch: 2 cost time: 4.187861919403076
Epoch: 2, Steps: 249 | Train Loss: 0.7293187 Vali Loss: 0.4807299 Test Loss: 0.4650602
Validation loss decreased (0.531234 --> 0.480730).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6115068
	speed: 0.0330s/iter; left time: 144.7844s
	iters: 200, epoch: 3 | loss: 0.7295619
	speed: 0.0182s/iter; left time: 77.7650s
Epoch: 3 cost time: 4.375284194946289
Epoch: 3, Steps: 249 | Train Loss: 0.6082483 Vali Loss: 0.4250985 Test Loss: 0.3851000
Validation loss decreased (0.480730 --> 0.425099).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5164523
	speed: 0.0339s/iter; left time: 140.1727s
	iters: 200, epoch: 4 | loss: 0.5462366
	speed: 0.0176s/iter; left time: 71.0972s
Epoch: 4 cost time: 4.3291847705841064
Epoch: 4, Steps: 249 | Train Loss: 0.5838460 Vali Loss: 0.4032274 Test Loss: 0.3867857
Validation loss decreased (0.425099 --> 0.403227).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.6836127
	speed: 0.0345s/iter; left time: 134.1531s
	iters: 200, epoch: 5 | loss: 0.6706613
	speed: 0.0166s/iter; left time: 62.9698s
Epoch: 5 cost time: 4.149699687957764
Epoch: 5, Steps: 249 | Train Loss: 0.5733959 Vali Loss: 0.3953907 Test Loss: 0.3796753
Validation loss decreased (0.403227 --> 0.395391).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4538009
	speed: 0.0329s/iter; left time: 119.6793s
	iters: 200, epoch: 6 | loss: 0.6735793
	speed: 0.0167s/iter; left time: 58.8928s
Epoch: 6 cost time: 4.059578895568848
Epoch: 6, Steps: 249 | Train Loss: 0.5662172 Vali Loss: 0.4010001 Test Loss: 0.3761555
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5534834
	speed: 0.0312s/iter; left time: 105.6267s
	iters: 200, epoch: 7 | loss: 0.5715692
	speed: 0.0170s/iter; left time: 55.8812s
Epoch: 7 cost time: 4.11594033241272
Epoch: 7, Steps: 249 | Train Loss: 0.5622044 Vali Loss: 0.3920154 Test Loss: 0.3773591
Validation loss decreased (0.395391 --> 0.392015).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5754473
	speed: 0.0345s/iter; left time: 108.2469s
	iters: 200, epoch: 8 | loss: 0.6813819
	speed: 0.0172s/iter; left time: 52.3961s
Epoch: 8 cost time: 4.1718363761901855
Epoch: 8, Steps: 249 | Train Loss: 0.5609800 Vali Loss: 0.3880578 Test Loss: 0.3774384
Validation loss decreased (0.392015 --> 0.388058).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.7536661
	speed: 0.0350s/iter; left time: 101.1397s
	iters: 200, epoch: 9 | loss: 0.3901281
	speed: 0.0175s/iter; left time: 48.8389s
Epoch: 9 cost time: 4.3055360317230225
Epoch: 9, Steps: 249 | Train Loss: 0.5600361 Vali Loss: 0.3954116 Test Loss: 0.3741342
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.6734344
	speed: 0.0309s/iter; left time: 81.6452s
	iters: 200, epoch: 10 | loss: 0.4904332
	speed: 0.0138s/iter; left time: 35.0351s
Epoch: 10 cost time: 3.5583155155181885
Epoch: 10, Steps: 249 | Train Loss: 0.5595135 Vali Loss: 0.3951463 Test Loss: 0.3738168
EarlyStopping counter: 2 out of 5
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.9814939
	speed: 0.0244s/iter; left time: 58.3868s
	iters: 200, epoch: 11 | loss: 0.6691413
	speed: 0.0122s/iter; left time: 27.8666s
Epoch: 11 cost time: 3.002213716506958
Epoch: 11, Steps: 249 | Train Loss: 0.5591126 Vali Loss: 0.3950529 Test Loss: 0.3742193
EarlyStopping counter: 3 out of 5
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5558116
	speed: 0.0209s/iter; left time: 44.8065s
	iters: 200, epoch: 12 | loss: 0.5292858
	speed: 0.0109s/iter; left time: 22.1722s
Epoch: 12 cost time: 2.6659417152404785
Epoch: 12, Steps: 249 | Train Loss: 0.5590889 Vali Loss: 0.3952491 Test Loss: 0.3741734
EarlyStopping counter: 4 out of 5
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.7569811
	speed: 0.0194s/iter; left time: 36.7487s
	iters: 200, epoch: 13 | loss: 0.8979695
	speed: 0.0103s/iter; left time: 18.4860s
Epoch: 13 cost time: 2.508131504058838
Epoch: 13, Steps: 249 | Train Loss: 0.5588813 Vali Loss: 0.3949831 Test Loss: 0.3742043
EarlyStopping counter: 5 out of 5
Early stopping
Total training time: 58.9470 seconds
>>>>>>>testing : ETTh2_336_336_NLinear_ETTh2_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed15726<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.37294480204582214, mae:0.41329991817474365
