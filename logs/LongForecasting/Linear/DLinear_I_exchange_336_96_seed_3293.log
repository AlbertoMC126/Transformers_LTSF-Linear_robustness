Args in experiment:
Namespace(activation='gelu', batch_size=8, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='exchange_rate.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=8, factor=1, features='M', freq='h', gpu=0, individual=True, is_training=1, itr=1, label_len=48, learning_rate=0.0005, loss='mse', lradj='type1', model='DLinear', model_id='Exchange_336_96', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=5, pred_len=96, root_path='./dataset/', save_pred_values=False, seed=3293, seq_len=336, target='OT', test_flop=False, train_epochs=20, train_only=False, use_amp=False, use_gpu=False, use_multi_gpu=False)
Use CPU
>>>>>>>start training : Exchange_336_96_DLinear_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed3293>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4880
val 665
test 1422
	iters: 100, epoch: 1 | loss: 0.3410497
	speed: 0.0057s/iter; left time: 69.1356s
	iters: 200, epoch: 1 | loss: 0.2113638
	speed: 0.0049s/iter; left time: 59.4048s
	iters: 300, epoch: 1 | loss: 0.2687236
	speed: 0.0057s/iter; left time: 67.9839s
	iters: 400, epoch: 1 | loss: 0.0802127
	speed: 0.0056s/iter; left time: 65.8567s
	iters: 500, epoch: 1 | loss: 0.0840936
	speed: 0.0058s/iter; left time: 68.2516s
	iters: 600, epoch: 1 | loss: 0.1960431
	speed: 0.0058s/iter; left time: 67.6394s
Epoch: 1 cost time: 3.4221622943878174
Epoch: 1, Steps: 610 | Train Loss: 0.1671248 Vali Loss: 0.3966854 Test Loss: 0.1829448
Validation loss decreased (inf --> 0.396685).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1457725
	speed: 0.0092s/iter; left time: 105.1712s
	iters: 200, epoch: 2 | loss: 0.1255796
	speed: 0.0055s/iter; left time: 62.3412s
	iters: 300, epoch: 2 | loss: 0.1436954
	speed: 0.0058s/iter; left time: 65.8266s
	iters: 400, epoch: 2 | loss: 0.4161136
	speed: 0.0066s/iter; left time: 73.3448s
	iters: 500, epoch: 2 | loss: 0.1301277
	speed: 0.0061s/iter; left time: 67.4548s
	iters: 600, epoch: 2 | loss: 0.1376388
	speed: 0.0064s/iter; left time: 70.3760s
Epoch: 2 cost time: 3.672231674194336
Epoch: 2, Steps: 610 | Train Loss: 0.1252940 Vali Loss: 0.3810820 Test Loss: 0.1727817
Validation loss decreased (0.396685 --> 0.381082).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.0741697
	speed: 0.0108s/iter; left time: 117.3261s
	iters: 200, epoch: 3 | loss: 0.0741819
	speed: 0.0067s/iter; left time: 72.1567s
	iters: 300, epoch: 3 | loss: 0.1304486
	speed: 0.0065s/iter; left time: 69.6663s
	iters: 400, epoch: 3 | loss: 0.1977611
	speed: 0.0066s/iter; left time: 70.0461s
	iters: 500, epoch: 3 | loss: 0.1505407
	speed: 0.0064s/iter; left time: 67.4087s
	iters: 600, epoch: 3 | loss: 0.1267498
	speed: 0.0055s/iter; left time: 56.8047s
Epoch: 3 cost time: 3.8919453620910645
Epoch: 3, Steps: 610 | Train Loss: 0.1148707 Vali Loss: 0.2076480 Test Loss: 0.1009517
Validation loss decreased (0.381082 --> 0.207648).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.0513447
	speed: 0.0111s/iter; left time: 113.5266s
	iters: 200, epoch: 4 | loss: 0.1463165
	speed: 0.0071s/iter; left time: 72.0106s
	iters: 300, epoch: 4 | loss: 0.0663833
	speed: 0.0061s/iter; left time: 61.8349s
	iters: 400, epoch: 4 | loss: 0.1132099
	speed: 0.0054s/iter; left time: 54.0637s
	iters: 500, epoch: 4 | loss: 0.0607834
	speed: 0.0059s/iter; left time: 58.7188s
	iters: 600, epoch: 4 | loss: 0.0547874
	speed: 0.0066s/iter; left time: 64.4132s
Epoch: 4 cost time: 3.8715953826904297
Epoch: 4, Steps: 610 | Train Loss: 0.1115294 Vali Loss: 0.2126446 Test Loss: 0.0990374
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2301959
	speed: 0.0098s/iter; left time: 94.2028s
	iters: 200, epoch: 5 | loss: 0.0745470
	speed: 0.0058s/iter; left time: 55.0767s
	iters: 300, epoch: 5 | loss: 0.1815695
	speed: 0.0062s/iter; left time: 58.6671s
	iters: 400, epoch: 5 | loss: 0.2045016
	speed: 0.0064s/iter; left time: 59.6456s
	iters: 500, epoch: 5 | loss: 0.0904849
	speed: 0.0060s/iter; left time: 55.2904s
	iters: 600, epoch: 5 | loss: 0.0787510
	speed: 0.0062s/iter; left time: 56.8198s
Epoch: 5 cost time: 3.7086668014526367
Epoch: 5, Steps: 610 | Train Loss: 0.1096746 Vali Loss: 0.1906348 Test Loss: 0.0887590
Validation loss decreased (0.207648 --> 0.190635).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2358031
	speed: 0.0097s/iter; left time: 87.5495s
	iters: 200, epoch: 6 | loss: 0.0844111
	speed: 0.0058s/iter; left time: 52.2737s
	iters: 300, epoch: 6 | loss: 0.1148350
	speed: 0.0059s/iter; left time: 52.1495s
	iters: 400, epoch: 6 | loss: 0.1827630
	speed: 0.0056s/iter; left time: 49.1071s
	iters: 500, epoch: 6 | loss: 0.1255413
	speed: 0.0055s/iter; left time: 47.4941s
	iters: 600, epoch: 6 | loss: 0.2604407
	speed: 0.0060s/iter; left time: 51.4178s
Epoch: 6 cost time: 3.5579545497894287
Epoch: 6, Steps: 610 | Train Loss: 0.1087887 Vali Loss: 0.2381552 Test Loss: 0.0912117
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.1069855
	speed: 0.0112s/iter; left time: 94.7229s
	iters: 200, epoch: 7 | loss: 0.0904829
	speed: 0.0064s/iter; left time: 53.3140s
	iters: 300, epoch: 7 | loss: 0.0819655
	speed: 0.0058s/iter; left time: 47.9665s
	iters: 400, epoch: 7 | loss: 0.0530523
	speed: 0.0065s/iter; left time: 53.0154s
	iters: 500, epoch: 7 | loss: 0.1520029
	speed: 0.0067s/iter; left time: 53.5428s
	iters: 600, epoch: 7 | loss: 0.0662811
	speed: 0.0059s/iter; left time: 46.7928s
Epoch: 7 cost time: 3.8267455101013184
Epoch: 7, Steps: 610 | Train Loss: 0.1082340 Vali Loss: 0.2061978 Test Loss: 0.0904077
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.0595287
	speed: 0.0094s/iter; left time: 73.4732s
	iters: 200, epoch: 8 | loss: 0.0905145
	speed: 0.0061s/iter; left time: 47.1093s
	iters: 300, epoch: 8 | loss: 0.0950804
	speed: 0.0059s/iter; left time: 45.3282s
	iters: 400, epoch: 8 | loss: 0.0692424
	speed: 0.0064s/iter; left time: 48.1418s
	iters: 500, epoch: 8 | loss: 0.1084848
	speed: 0.0070s/iter; left time: 51.9427s
	iters: 600, epoch: 8 | loss: 0.1029607
	speed: 0.0061s/iter; left time: 44.4506s
Epoch: 8 cost time: 3.7821779251098633
Epoch: 8, Steps: 610 | Train Loss: 0.1080188 Vali Loss: 0.1995588 Test Loss: 0.0890428
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.0631220
	speed: 0.0101s/iter; left time: 72.7294s
	iters: 200, epoch: 9 | loss: 0.0820136
	speed: 0.0069s/iter; left time: 49.4349s
	iters: 300, epoch: 9 | loss: 0.1234164
	speed: 0.0066s/iter; left time: 46.6213s
	iters: 400, epoch: 9 | loss: 0.0641861
	speed: 0.0065s/iter; left time: 44.8008s
	iters: 500, epoch: 9 | loss: 0.1060349
	speed: 0.0064s/iter; left time: 43.6702s
	iters: 600, epoch: 9 | loss: 0.0639602
	speed: 0.0064s/iter; left time: 42.9472s
Epoch: 9 cost time: 3.9969804286956787
Epoch: 9, Steps: 610 | Train Loss: 0.1079004 Vali Loss: 0.1978711 Test Loss: 0.0883904
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.0717218
	speed: 0.0108s/iter; left time: 71.0756s
	iters: 200, epoch: 10 | loss: 0.0927579
	speed: 0.0064s/iter; left time: 41.7477s
	iters: 300, epoch: 10 | loss: 0.1270401
	speed: 0.0058s/iter; left time: 37.1994s
	iters: 400, epoch: 10 | loss: 0.1045532
	speed: 0.0064s/iter; left time: 40.4536s
	iters: 500, epoch: 10 | loss: 0.2463063
	speed: 0.0058s/iter; left time: 35.7904s
	iters: 600, epoch: 10 | loss: 0.1162777
	speed: 0.0055s/iter; left time: 33.4272s
Epoch: 10 cost time: 3.7055156230926514
Epoch: 10, Steps: 610 | Train Loss: 0.1077998 Vali Loss: 0.2001902 Test Loss: 0.0892797
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : Exchange_336_96_DLinear_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0_seed3293<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1422
mse:0.0886196419596672, mae:0.2175666242837906
