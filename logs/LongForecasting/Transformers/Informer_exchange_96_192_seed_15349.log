Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=8, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='exchange_rate.csv', dec_in=8, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=8, factor=3, features='M', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Informer', model_id='exchange_192', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=15349, seq_len=96, target='OT', test_flop=False, train_epochs=10, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : exchange_192_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed15349>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5024
val 569
test 1326
	iters: 100, epoch: 1 | loss: 0.1108023
	speed: 0.0633s/iter; left time: 93.0851s
Epoch: 1 cost time: 8.216511726379395
Epoch: 1, Steps: 157 | Train Loss: 0.1862411 Vali Loss: 1.4149193 Test Loss: 1.3334196
Validation loss decreased (inf --> 1.414919).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0733480
	speed: 0.0609s/iter; left time: 80.0336s
Epoch: 2 cost time: 5.156124114990234
Epoch: 2, Steps: 157 | Train Loss: 0.0813337 Vali Loss: 1.2435274 Test Loss: 1.2871590
Validation loss decreased (1.414919 --> 1.243527).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.0598536
	speed: 0.0610s/iter; left time: 70.5390s
Epoch: 3 cost time: 5.183959484100342
Epoch: 3, Steps: 157 | Train Loss: 0.0588527 Vali Loss: 1.0659753 Test Loss: 1.1350607
Validation loss decreased (1.243527 --> 1.065975).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.0498650
	speed: 0.0614s/iter; left time: 61.4043s
Epoch: 4 cost time: 5.206600666046143
Epoch: 4, Steps: 157 | Train Loss: 0.0514923 Vali Loss: 1.0614657 Test Loss: 1.1362005
Validation loss decreased (1.065975 --> 1.061466).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.0495279
	speed: 0.0620s/iter; left time: 52.2372s
Epoch: 5 cost time: 5.199727535247803
Epoch: 5, Steps: 157 | Train Loss: 0.0470393 Vali Loss: 1.0879916 Test Loss: 1.1828908
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.0451961
	speed: 0.0591s/iter; left time: 40.5647s
Epoch: 6 cost time: 5.195615530014038
Epoch: 6, Steps: 157 | Train Loss: 0.0456649 Vali Loss: 1.0607021 Test Loss: 1.1457639
Validation loss decreased (1.061466 --> 1.060702).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.0431105
	speed: 0.0613s/iter; left time: 32.4353s
Epoch: 7 cost time: 5.17907190322876
Epoch: 7, Steps: 157 | Train Loss: 0.0449214 Vali Loss: 1.0560491 Test Loss: 1.1392560
Validation loss decreased (1.060702 --> 1.056049).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.0430249
	speed: 0.0623s/iter; left time: 23.1940s
Epoch: 8 cost time: 5.216322660446167
Epoch: 8, Steps: 157 | Train Loss: 0.0440997 Vali Loss: 1.0635287 Test Loss: 1.1406672
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.0441772
	speed: 0.0593s/iter; left time: 12.7518s
Epoch: 9 cost time: 5.205858469009399
Epoch: 9, Steps: 157 | Train Loss: 0.0435139 Vali Loss: 1.0667093 Test Loss: 1.1449286
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.0494993
	speed: 0.0589s/iter; left time: 3.4134s
Epoch: 10 cost time: 5.175275087356567
Epoch: 10, Steps: 157 | Train Loss: 0.0438594 Vali Loss: 1.0572392 Test Loss: 1.1480036
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : exchange_192_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed15349<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1326
mse:1.1420531272888184, mae:0.8506379723548889
