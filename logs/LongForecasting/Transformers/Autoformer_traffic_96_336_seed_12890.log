Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=862, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', dec_in=862, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=3, features='M', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Autoformer', model_id='traffic_336', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=12890, seq_len=96, target='OT', test_flop=False, train_epochs=10, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : traffic_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed12890>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11849
val 1421
test 3173
	iters: 100, epoch: 1 | loss: 0.4724239
	speed: 0.1616s/iter; left time: 581.9052s
	iters: 200, epoch: 1 | loss: 0.3724221
	speed: 0.1262s/iter; left time: 441.9421s
	iters: 300, epoch: 1 | loss: 0.3269397
	speed: 0.1263s/iter; left time: 429.6800s
Epoch: 1 cost time: 50.32567000389099
Epoch: 1, Steps: 370 | Train Loss: 0.4340592 Vali Loss: 0.5085673 Test Loss: 0.6578920
Validation loss decreased (inf --> 0.508567).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3073506
	speed: 0.4112s/iter; left time: 1328.4384s
	iters: 200, epoch: 2 | loss: 0.2984168
	speed: 0.1268s/iter; left time: 396.8894s
	iters: 300, epoch: 2 | loss: 0.2869345
	speed: 0.1262s/iter; left time: 382.3769s
Epoch: 2 cost time: 46.81061410903931
Epoch: 2, Steps: 370 | Train Loss: 0.2981926 Vali Loss: 0.4851858 Test Loss: 0.6346101
Validation loss decreased (0.508567 --> 0.485186).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2646435
	speed: 0.4115s/iter; left time: 1177.4332s
	iters: 200, epoch: 3 | loss: 0.2601260
	speed: 0.1266s/iter; left time: 349.6195s
	iters: 300, epoch: 3 | loss: 0.2623137
	speed: 0.1261s/iter; left time: 335.4807s
Epoch: 3 cost time: 46.76861071586609
Epoch: 3, Steps: 370 | Train Loss: 0.2624645 Vali Loss: 0.4618239 Test Loss: 0.6071854
Validation loss decreased (0.485186 --> 0.461824).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2579125
	speed: 0.4106s/iter; left time: 1022.7270s
	iters: 200, epoch: 4 | loss: 0.2534605
	speed: 0.1264s/iter; left time: 302.2326s
	iters: 300, epoch: 4 | loss: 0.2487634
	speed: 0.1266s/iter; left time: 289.9892s
Epoch: 4 cost time: 46.81155180931091
Epoch: 4, Steps: 370 | Train Loss: 0.2516766 Vali Loss: 0.4601381 Test Loss: 0.6109939
Validation loss decreased (0.461824 --> 0.460138).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2546130
	speed: 0.4113s/iter; left time: 872.4341s
	iters: 200, epoch: 5 | loss: 0.2403254
	speed: 0.1262s/iter; left time: 255.0082s
	iters: 300, epoch: 5 | loss: 0.2506690
	speed: 0.1262s/iter; left time: 242.4357s
Epoch: 5 cost time: 46.69032001495361
Epoch: 5, Steps: 370 | Train Loss: 0.2475887 Vali Loss: 0.4587517 Test Loss: 0.6089384
Validation loss decreased (0.460138 --> 0.458752).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2343504
	speed: 0.4102s/iter; left time: 718.2809s
	iters: 200, epoch: 6 | loss: 0.2372494
	speed: 0.1264s/iter; left time: 208.6692s
	iters: 300, epoch: 6 | loss: 0.2379209
	speed: 0.1262s/iter; left time: 195.6962s
Epoch: 6 cost time: 46.7188515663147
Epoch: 6, Steps: 370 | Train Loss: 0.2454269 Vali Loss: 0.4574119 Test Loss: 0.6115742
Validation loss decreased (0.458752 --> 0.457412).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2490734
	speed: 0.4122s/iter; left time: 569.1894s
	iters: 200, epoch: 7 | loss: 0.2469824
	speed: 0.1261s/iter; left time: 161.5128s
	iters: 300, epoch: 7 | loss: 0.2470274
	speed: 0.1266s/iter; left time: 149.5168s
Epoch: 7 cost time: 46.79188060760498
Epoch: 7, Steps: 370 | Train Loss: 0.2442727 Vali Loss: 0.4596387 Test Loss: 0.6128806
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2369962
	speed: 0.4086s/iter; left time: 413.0938s
	iters: 200, epoch: 8 | loss: 0.2524825
	speed: 0.1263s/iter; left time: 115.0375s
	iters: 300, epoch: 8 | loss: 0.2562951
	speed: 0.1264s/iter; left time: 102.5012s
Epoch: 8 cost time: 46.7601432800293
Epoch: 8, Steps: 370 | Train Loss: 0.2436994 Vali Loss: 0.4575858 Test Loss: 0.6102368
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2418715
	speed: 0.4075s/iter; left time: 261.1787s
	iters: 200, epoch: 9 | loss: 0.2373166
	speed: 0.1260s/iter; left time: 68.1448s
	iters: 300, epoch: 9 | loss: 0.2518556
	speed: 0.1258s/iter; left time: 55.4868s
Epoch: 9 cost time: 46.65363621711731
Epoch: 9, Steps: 370 | Train Loss: 0.2432894 Vali Loss: 0.4565787 Test Loss: 0.6094412
Validation loss decreased (0.457412 --> 0.456579).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2376992
	speed: 0.4100s/iter; left time: 111.0978s
	iters: 200, epoch: 10 | loss: 0.2358727
	speed: 0.1266s/iter; left time: 21.6562s
	iters: 300, epoch: 10 | loss: 0.2470406
	speed: 0.1267s/iter; left time: 8.9992s
Epoch: 10 cost time: 46.82470107078552
Epoch: 10, Steps: 370 | Train Loss: 0.2431341 Vali Loss: 0.4569520 Test Loss: 0.6099319
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : traffic_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed12890<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3173
mse:0.6081177592277527, mae:0.3768545091152191
