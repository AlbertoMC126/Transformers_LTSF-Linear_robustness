Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=862, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='traffic.csv', dec_in=862, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=862, factor=3, features='M', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Autoformer', model_id='traffic_336', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=15349, seq_len=96, target='OT', test_flop=False, train_epochs=10, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : traffic_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed15349>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11849
val 1421
test 3173
	iters: 100, epoch: 1 | loss: 0.4673812
	speed: 0.1580s/iter; left time: 569.0262s
	iters: 200, epoch: 1 | loss: 0.3539410
	speed: 0.1263s/iter; left time: 442.2913s
	iters: 300, epoch: 1 | loss: 0.3067718
	speed: 0.1264s/iter; left time: 429.8889s
Epoch: 1 cost time: 49.87783122062683
Epoch: 1, Steps: 370 | Train Loss: 0.4207350 Vali Loss: 0.5158525 Test Loss: 0.6594552
Validation loss decreased (inf --> 0.515853).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2776284
	speed: 0.4025s/iter; left time: 1300.3222s
	iters: 200, epoch: 2 | loss: 0.2794060
	speed: 0.1261s/iter; left time: 394.8411s
	iters: 300, epoch: 2 | loss: 0.2719007
	speed: 0.1251s/iter; left time: 379.0727s
Epoch: 2 cost time: 46.4321014881134
Epoch: 2, Steps: 370 | Train Loss: 0.2865934 Vali Loss: 0.4905824 Test Loss: 0.6601243
Validation loss decreased (0.515853 --> 0.490582).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2662868
	speed: 0.4052s/iter; left time: 1159.1488s
	iters: 200, epoch: 3 | loss: 0.2622081
	speed: 0.1264s/iter; left time: 348.9964s
	iters: 300, epoch: 3 | loss: 0.2625252
	speed: 0.1257s/iter; left time: 334.4795s
Epoch: 3 cost time: 46.724682569503784
Epoch: 3, Steps: 370 | Train Loss: 0.2639106 Vali Loss: 0.4898925 Test Loss: 0.6378761
Validation loss decreased (0.490582 --> 0.489893).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2478941
	speed: 0.4037s/iter; left time: 1005.7412s
	iters: 200, epoch: 4 | loss: 0.2456563
	speed: 0.1252s/iter; left time: 299.4084s
	iters: 300, epoch: 4 | loss: 0.2585192
	speed: 0.1251s/iter; left time: 286.4899s
Epoch: 4 cost time: 46.32157921791077
Epoch: 4, Steps: 370 | Train Loss: 0.2544976 Vali Loss: 0.4849306 Test Loss: 0.6337101
Validation loss decreased (0.489893 --> 0.484931).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2498408
	speed: 0.4060s/iter; left time: 861.2132s
	iters: 200, epoch: 5 | loss: 0.2485891
	speed: 0.1257s/iter; left time: 254.0698s
	iters: 300, epoch: 5 | loss: 0.2560947
	speed: 0.1246s/iter; left time: 239.2734s
Epoch: 5 cost time: 46.39621567726135
Epoch: 5, Steps: 370 | Train Loss: 0.2496118 Vali Loss: 0.4817211 Test Loss: 0.6313702
Validation loss decreased (0.484931 --> 0.481721).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2470315
	speed: 0.4015s/iter; left time: 703.0908s
	iters: 200, epoch: 6 | loss: 0.2472804
	speed: 0.1251s/iter; left time: 206.5364s
	iters: 300, epoch: 6 | loss: 0.2560295
	speed: 0.1247s/iter; left time: 193.3547s
Epoch: 6 cost time: 46.27291440963745
Epoch: 6, Steps: 370 | Train Loss: 0.2470233 Vali Loss: 0.4801361 Test Loss: 0.6356623
Validation loss decreased (0.481721 --> 0.480136).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2476199
	speed: 0.4060s/iter; left time: 560.7383s
	iters: 200, epoch: 7 | loss: 0.2415671
	speed: 0.1252s/iter; left time: 160.3505s
	iters: 300, epoch: 7 | loss: 0.2452027
	speed: 0.1250s/iter; left time: 147.6391s
Epoch: 7 cost time: 46.3836669921875
Epoch: 7, Steps: 370 | Train Loss: 0.2455664 Vali Loss: 0.4810807 Test Loss: 0.6326740
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2441673
	speed: 0.4009s/iter; left time: 405.2817s
	iters: 200, epoch: 8 | loss: 0.2438870
	speed: 0.1252s/iter; left time: 114.0586s
	iters: 300, epoch: 8 | loss: 0.2469784
	speed: 0.1256s/iter; left time: 101.8776s
Epoch: 8 cost time: 46.50148606300354
Epoch: 8, Steps: 370 | Train Loss: 0.2447721 Vali Loss: 0.4808600 Test Loss: 0.6337450
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2438805
	speed: 0.4032s/iter; left time: 258.4372s
	iters: 200, epoch: 9 | loss: 0.2480973
	speed: 0.1251s/iter; left time: 67.6989s
	iters: 300, epoch: 9 | loss: 0.2506963
	speed: 0.1254s/iter; left time: 55.2999s
Epoch: 9 cost time: 46.36508846282959
Epoch: 9, Steps: 370 | Train Loss: 0.2442891 Vali Loss: 0.4827838 Test Loss: 0.6344151
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : traffic_336_Autoformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed15349<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3173
mse:0.6348200440406799, mae:0.3967934250831604
