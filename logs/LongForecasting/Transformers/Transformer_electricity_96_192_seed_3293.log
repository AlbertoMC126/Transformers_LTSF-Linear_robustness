Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=321, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', dec_in=321, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=3, features='M', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Transformer', model_id='electricity_192', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seed=3293, seq_len=96, target='OT', test_flop=False, train_epochs=10, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : electricity_192_Transformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed3293>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18125
val 2441
test 5069
	iters: 100, epoch: 1 | loss: 0.3290427
	speed: 0.0668s/iter; left time: 371.5036s
	iters: 200, epoch: 1 | loss: 0.2615041
	speed: 0.0361s/iter; left time: 197.0207s
	iters: 300, epoch: 1 | loss: 0.2390634
	speed: 0.0360s/iter; left time: 192.8785s
	iters: 400, epoch: 1 | loss: 0.2040119
	speed: 0.0360s/iter; left time: 189.3276s
	iters: 500, epoch: 1 | loss: 0.2310761
	speed: 0.0363s/iter; left time: 187.3127s
Epoch: 1 cost time: 23.510810613632202
Epoch: 1, Steps: 566 | Train Loss: 0.2939119 Vali Loss: 0.2420757 Test Loss: 0.3138850
Validation loss decreased (inf --> 0.242076).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1851645
	speed: 0.1279s/iter; left time: 638.7806s
	iters: 200, epoch: 2 | loss: 0.1698514
	speed: 0.0365s/iter; left time: 178.4364s
	iters: 300, epoch: 2 | loss: 0.1551157
	speed: 0.0363s/iter; left time: 174.1565s
	iters: 400, epoch: 2 | loss: 0.1546580
	speed: 0.0365s/iter; left time: 171.2319s
	iters: 500, epoch: 2 | loss: 0.1353922
	speed: 0.0362s/iter; left time: 166.4882s
Epoch: 2 cost time: 20.55639362335205
Epoch: 2, Steps: 566 | Train Loss: 0.1633869 Vali Loss: 0.2036849 Test Loss: 0.2713601
Validation loss decreased (0.242076 --> 0.203685).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1455150
	speed: 0.1267s/iter; left time: 561.2350s
	iters: 200, epoch: 3 | loss: 0.1409848
	speed: 0.0362s/iter; left time: 156.7865s
	iters: 300, epoch: 3 | loss: 0.1372112
	speed: 0.0362s/iter; left time: 153.0860s
	iters: 400, epoch: 3 | loss: 0.1373367
	speed: 0.0362s/iter; left time: 149.3331s
	iters: 500, epoch: 3 | loss: 0.1356788
	speed: 0.0361s/iter; left time: 145.5810s
Epoch: 3 cost time: 20.464378595352173
Epoch: 3, Steps: 566 | Train Loss: 0.1339546 Vali Loss: 0.2038640 Test Loss: 0.2833593
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1286010
	speed: 0.1243s/iter; left time: 480.1047s
	iters: 200, epoch: 4 | loss: 0.1306449
	speed: 0.0363s/iter; left time: 136.7048s
	iters: 300, epoch: 4 | loss: 0.1287245
	speed: 0.0362s/iter; left time: 132.7318s
	iters: 400, epoch: 4 | loss: 0.1222764
	speed: 0.0361s/iter; left time: 128.8003s
	iters: 500, epoch: 4 | loss: 0.1231824
	speed: 0.0364s/iter; left time: 125.8833s
Epoch: 4 cost time: 20.511510610580444
Epoch: 4, Steps: 566 | Train Loss: 0.1245410 Vali Loss: 0.2068219 Test Loss: 0.2809373
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1203657
	speed: 0.1249s/iter; left time: 411.8641s
	iters: 200, epoch: 5 | loss: 0.1177401
	speed: 0.0364s/iter; left time: 116.2482s
	iters: 300, epoch: 5 | loss: 0.1189698
	speed: 0.0364s/iter; left time: 112.7671s
	iters: 400, epoch: 5 | loss: 0.1168674
	speed: 0.0362s/iter; left time: 108.5458s
	iters: 500, epoch: 5 | loss: 0.1219731
	speed: 0.0362s/iter; left time: 104.9304s
Epoch: 5 cost time: 20.536348819732666
Epoch: 5, Steps: 566 | Train Loss: 0.1195333 Vali Loss: 0.2021271 Test Loss: 0.2754974
Validation loss decreased (0.203685 --> 0.202127).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.1171370
	speed: 0.1269s/iter; left time: 346.5304s
	iters: 200, epoch: 6 | loss: 0.1165463
	speed: 0.0362s/iter; left time: 95.3576s
	iters: 300, epoch: 6 | loss: 0.1138147
	speed: 0.0363s/iter; left time: 91.7897s
	iters: 400, epoch: 6 | loss: 0.1199127
	speed: 0.0362s/iter; left time: 88.0191s
	iters: 500, epoch: 6 | loss: 0.1181413
	speed: 0.0363s/iter; left time: 84.6376s
Epoch: 6 cost time: 20.50502896308899
Epoch: 6, Steps: 566 | Train Loss: 0.1169229 Vali Loss: 0.2023918 Test Loss: 0.2734324
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1146542
	speed: 0.1251s/iter; left time: 270.9461s
	iters: 200, epoch: 7 | loss: 0.1138049
	speed: 0.0363s/iter; left time: 74.9776s
	iters: 300, epoch: 7 | loss: 0.1202709
	speed: 0.0364s/iter; left time: 71.4842s
	iters: 400, epoch: 7 | loss: 0.1141399
	speed: 0.0361s/iter; left time: 67.4193s
	iters: 500, epoch: 7 | loss: 0.1233127
	speed: 0.0361s/iter; left time: 63.7242s
Epoch: 7 cost time: 20.50923180580139
Epoch: 7, Steps: 566 | Train Loss: 0.1156042 Vali Loss: 0.2023160 Test Loss: 0.2748441
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.1116870
	speed: 0.1246s/iter; left time: 199.2309s
	iters: 200, epoch: 8 | loss: 0.1131347
	speed: 0.0362s/iter; left time: 54.2406s
	iters: 300, epoch: 8 | loss: 0.1172178
	speed: 0.0363s/iter; left time: 50.7484s
	iters: 400, epoch: 8 | loss: 0.1198309
	speed: 0.0362s/iter; left time: 46.9756s
	iters: 500, epoch: 8 | loss: 0.1144742
	speed: 0.0362s/iter; left time: 43.3892s
Epoch: 8 cost time: 20.4860098361969
Epoch: 8, Steps: 566 | Train Loss: 0.1148699 Vali Loss: 0.2025059 Test Loss: 0.2738412
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : electricity_192_Transformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed3293<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.27415144443511963, mae:0.37390056252479553
