Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, features='M', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Autoformer', model_id='ETTm1_336', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=15726, seq_len=96, target='OT', test_flop=False, train_epochs=10, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_336_Autoformer_ETTm1_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed15726>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4829873
	speed: 0.1164s/iter; left time: 1229.7885s
	iters: 200, epoch: 1 | loss: 0.4619119
	speed: 0.0829s/iter; left time: 867.0743s
	iters: 300, epoch: 1 | loss: 0.4664100
	speed: 0.0830s/iter; left time: 860.3825s
	iters: 400, epoch: 1 | loss: 0.4625975
	speed: 0.0831s/iter; left time: 852.2797s
	iters: 500, epoch: 1 | loss: 0.4649332
	speed: 0.0827s/iter; left time: 840.4774s
	iters: 600, epoch: 1 | loss: 0.3536383
	speed: 0.0826s/iter; left time: 831.3138s
	iters: 700, epoch: 1 | loss: 0.4090167
	speed: 0.0827s/iter; left time: 823.3270s
	iters: 800, epoch: 1 | loss: 0.3918782
	speed: 0.0826s/iter; left time: 814.6847s
	iters: 900, epoch: 1 | loss: 0.3463995
	speed: 0.0826s/iter; left time: 806.6569s
	iters: 1000, epoch: 1 | loss: 0.3227107
	speed: 0.0826s/iter; left time: 797.5828s
Epoch: 1 cost time: 91.61891460418701
Epoch: 1, Steps: 1066 | Train Loss: 0.4305086 Vali Loss: 0.8197342 Test Loss: 0.6268285
Validation loss decreased (inf --> 0.819734).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3822502
	speed: 0.5178s/iter; left time: 4916.3337s
	iters: 200, epoch: 2 | loss: 0.3400907
	speed: 0.0829s/iter; left time: 779.1612s
	iters: 300, epoch: 2 | loss: 0.2990938
	speed: 0.0830s/iter; left time: 771.3452s
	iters: 400, epoch: 2 | loss: 0.3088557
	speed: 0.0828s/iter; left time: 761.2087s
	iters: 500, epoch: 2 | loss: 0.3740764
	speed: 0.0824s/iter; left time: 749.6679s
	iters: 600, epoch: 2 | loss: 0.4221768
	speed: 0.0824s/iter; left time: 741.5862s
	iters: 700, epoch: 2 | loss: 0.3548819
	speed: 0.0825s/iter; left time: 734.2697s
	iters: 800, epoch: 2 | loss: 0.4272389
	speed: 0.0824s/iter; left time: 725.0585s
	iters: 900, epoch: 2 | loss: 0.3765279
	speed: 0.0824s/iter; left time: 716.8589s
	iters: 1000, epoch: 2 | loss: 0.3167453
	speed: 0.0825s/iter; left time: 708.9854s
Epoch: 2 cost time: 88.07701468467712
Epoch: 2, Steps: 1066 | Train Loss: 0.3469110 Vali Loss: 0.8738384 Test Loss: 0.6778796
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3158150
	speed: 0.5168s/iter; left time: 4356.1736s
	iters: 200, epoch: 3 | loss: 0.3576771
	speed: 0.0831s/iter; left time: 692.1307s
	iters: 300, epoch: 3 | loss: 0.3325372
	speed: 0.0828s/iter; left time: 681.0567s
	iters: 400, epoch: 3 | loss: 0.3554583
	speed: 0.0825s/iter; left time: 670.9224s
	iters: 500, epoch: 3 | loss: 0.3188727
	speed: 0.0825s/iter; left time: 662.7527s
	iters: 600, epoch: 3 | loss: 0.3063245
	speed: 0.0825s/iter; left time: 654.0825s
	iters: 700, epoch: 3 | loss: 0.2782814
	speed: 0.0827s/iter; left time: 647.1383s
	iters: 800, epoch: 3 | loss: 0.3537500
	speed: 0.0826s/iter; left time: 638.6172s
	iters: 900, epoch: 3 | loss: 0.2545368
	speed: 0.0826s/iter; left time: 629.9986s
	iters: 1000, epoch: 3 | loss: 0.3617471
	speed: 0.0827s/iter; left time: 622.5213s
Epoch: 3 cost time: 88.15546679496765
Epoch: 3, Steps: 1066 | Train Loss: 0.3130856 Vali Loss: 0.8975157 Test Loss: 0.7136762
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3128580
	speed: 0.5175s/iter; left time: 3810.3026s
	iters: 200, epoch: 4 | loss: 0.2405804
	speed: 0.0827s/iter; left time: 600.4685s
	iters: 300, epoch: 4 | loss: 0.3664877
	speed: 0.0826s/iter; left time: 591.9349s
	iters: 400, epoch: 4 | loss: 0.3010699
	speed: 0.0825s/iter; left time: 583.0317s
	iters: 500, epoch: 4 | loss: 0.2843241
	speed: 0.0825s/iter; left time: 574.6918s
	iters: 600, epoch: 4 | loss: 0.2523249
	speed: 0.0825s/iter; left time: 566.4262s
	iters: 700, epoch: 4 | loss: 0.2986858
	speed: 0.0825s/iter; left time: 558.0781s
	iters: 800, epoch: 4 | loss: 0.2847849
	speed: 0.0825s/iter; left time: 549.3822s
	iters: 900, epoch: 4 | loss: 0.2633722
	speed: 0.0825s/iter; left time: 541.6000s
	iters: 1000, epoch: 4 | loss: 0.2949865
	speed: 0.0824s/iter; left time: 532.5738s
Epoch: 4 cost time: 88.03368711471558
Epoch: 4, Steps: 1066 | Train Loss: 0.2948895 Vali Loss: 0.9000344 Test Loss: 0.6919714
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_336_Autoformer_ETTm1_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed15726<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.6262669563293457, mae:0.529198169708252
