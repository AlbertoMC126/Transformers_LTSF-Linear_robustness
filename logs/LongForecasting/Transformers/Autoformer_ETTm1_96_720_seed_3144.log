Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTm1', data_path='ETTm1.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, features='M', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Autoformer', model_id='ETTm1_720', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=3, pred_len=720, root_path='./dataset/', seed=3144, seq_len=96, target='OT', test_flop=False, train_epochs=10, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_720_Autoformer_ETTm1_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed3144>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4330672
	speed: 0.1770s/iter; left time: 1847.7468s
	iters: 200, epoch: 1 | loss: 0.4500284
	speed: 0.1427s/iter; left time: 1475.6084s
	iters: 300, epoch: 1 | loss: 0.4948075
	speed: 0.1428s/iter; left time: 1462.4330s
	iters: 400, epoch: 1 | loss: 0.4568433
	speed: 0.1430s/iter; left time: 1450.1729s
	iters: 500, epoch: 1 | loss: 0.4112524
	speed: 0.1429s/iter; left time: 1434.9346s
	iters: 600, epoch: 1 | loss: 0.4291751
	speed: 0.1427s/iter; left time: 1418.6249s
	iters: 700, epoch: 1 | loss: 0.4945050
	speed: 0.1428s/iter; left time: 1404.9639s
	iters: 800, epoch: 1 | loss: 0.4152743
	speed: 0.1428s/iter; left time: 1390.5395s
	iters: 900, epoch: 1 | loss: 0.4401871
	speed: 0.1426s/iter; left time: 1374.9022s
	iters: 1000, epoch: 1 | loss: 0.4364009
	speed: 0.1427s/iter; left time: 1361.8311s
Epoch: 1 cost time: 153.99137830734253
Epoch: 1, Steps: 1054 | Train Loss: 0.4824417 Vali Loss: 1.1697398 Test Loss: 0.6373134
Validation loss decreased (inf --> 1.169740).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4744599
	speed: 0.9017s/iter; left time: 8464.6517s
	iters: 200, epoch: 2 | loss: 0.3876536
	speed: 0.1425s/iter; left time: 1323.4542s
	iters: 300, epoch: 2 | loss: 0.4031758
	speed: 0.1424s/iter; left time: 1307.7827s
	iters: 400, epoch: 2 | loss: 0.4752284
	speed: 0.1425s/iter; left time: 1294.7888s
	iters: 500, epoch: 2 | loss: 0.3873059
	speed: 0.1429s/iter; left time: 1283.9124s
	iters: 600, epoch: 2 | loss: 0.4309369
	speed: 0.1427s/iter; left time: 1268.5612s
	iters: 700, epoch: 2 | loss: 0.5128377
	speed: 0.1428s/iter; left time: 1254.6534s
	iters: 800, epoch: 2 | loss: 0.3496626
	speed: 0.1427s/iter; left time: 1239.6046s
	iters: 900, epoch: 2 | loss: 0.4404232
	speed: 0.1428s/iter; left time: 1226.2574s
	iters: 1000, epoch: 2 | loss: 0.3532319
	speed: 0.1427s/iter; left time: 1211.0947s
Epoch: 2 cost time: 150.34064316749573
Epoch: 2, Steps: 1054 | Train Loss: 0.4233695 Vali Loss: 1.2357229 Test Loss: 0.6958061
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4622557
	speed: 0.8974s/iter; left time: 7477.7268s
	iters: 200, epoch: 3 | loss: 0.4781499
	speed: 0.1426s/iter; left time: 1174.2454s
	iters: 300, epoch: 3 | loss: 0.4699096
	speed: 0.1427s/iter; left time: 1160.9678s
	iters: 400, epoch: 3 | loss: 0.3991899
	speed: 0.1427s/iter; left time: 1146.3066s
	iters: 500, epoch: 3 | loss: 0.4373202
	speed: 0.1427s/iter; left time: 1132.1248s
	iters: 600, epoch: 3 | loss: 0.3864500
	speed: 0.1427s/iter; left time: 1117.4462s
	iters: 700, epoch: 3 | loss: 0.3350195
	speed: 0.1428s/iter; left time: 1103.9974s
	iters: 800, epoch: 3 | loss: 0.4067455
	speed: 0.1428s/iter; left time: 1090.1626s
	iters: 900, epoch: 3 | loss: 0.3928704
	speed: 0.1427s/iter; left time: 1075.2090s
	iters: 1000, epoch: 3 | loss: 0.3412990
	speed: 0.1427s/iter; left time: 1060.6513s
Epoch: 3 cost time: 150.4031593799591
Epoch: 3, Steps: 1054 | Train Loss: 0.3888577 Vali Loss: 1.2350982 Test Loss: 0.6790715
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3319720
	speed: 0.8974s/iter; left time: 6531.9619s
	iters: 200, epoch: 4 | loss: 0.3651090
	speed: 0.1427s/iter; left time: 1024.0888s
	iters: 300, epoch: 4 | loss: 0.3868209
	speed: 0.1427s/iter; left time: 1010.0710s
	iters: 400, epoch: 4 | loss: 0.3550612
	speed: 0.1427s/iter; left time: 996.1379s
	iters: 500, epoch: 4 | loss: 0.3777199
	speed: 0.1428s/iter; left time: 982.5534s
	iters: 600, epoch: 4 | loss: 0.4213319
	speed: 0.1426s/iter; left time: 966.3860s
	iters: 700, epoch: 4 | loss: 0.3788670
	speed: 0.1426s/iter; left time: 952.5129s
	iters: 800, epoch: 4 | loss: 0.3733374
	speed: 0.1427s/iter; left time: 939.1252s
	iters: 900, epoch: 4 | loss: 0.3926552
	speed: 0.1428s/iter; left time: 925.4654s
	iters: 1000, epoch: 4 | loss: 0.4252292
	speed: 0.1427s/iter; left time: 910.0720s
Epoch: 4 cost time: 150.4032711982727
Epoch: 4, Steps: 1054 | Train Loss: 0.3732534 Vali Loss: 1.2532073 Test Loss: 0.6917362
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_Autoformer_ETTm1_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed3144<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.6369659900665283, mae:0.5320850610733032
