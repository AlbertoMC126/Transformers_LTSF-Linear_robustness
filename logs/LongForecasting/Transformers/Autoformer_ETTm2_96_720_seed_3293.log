Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, features='M', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Autoformer', model_id='ETTm2_720', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=3, pred_len=720, root_path='./dataset/', seed=3293, seq_len=96, target='OT', test_flop=False, train_epochs=10, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_Autoformer_ETTm2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed3293>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.5273740
	speed: 0.1773s/iter; left time: 1851.1543s
	iters: 200, epoch: 1 | loss: 0.2949490
	speed: 0.1428s/iter; left time: 1476.4974s
	iters: 300, epoch: 1 | loss: 0.4110027
	speed: 0.1431s/iter; left time: 1465.4989s
	iters: 400, epoch: 1 | loss: 1.0333463
	speed: 0.1432s/iter; left time: 1452.2222s
	iters: 500, epoch: 1 | loss: 0.7890748
	speed: 0.1431s/iter; left time: 1437.0392s
	iters: 600, epoch: 1 | loss: 0.6195884
	speed: 0.1430s/iter; left time: 1421.4235s
	iters: 700, epoch: 1 | loss: 0.6499668
	speed: 0.1429s/iter; left time: 1406.7496s
	iters: 800, epoch: 1 | loss: 0.4220700
	speed: 0.1429s/iter; left time: 1392.4299s
	iters: 900, epoch: 1 | loss: 0.3414039
	speed: 0.1428s/iter; left time: 1376.3142s
	iters: 1000, epoch: 1 | loss: 1.0339715
	speed: 0.1426s/iter; left time: 1360.4909s
Epoch: 1 cost time: 154.16238927841187
Epoch: 1, Steps: 1054 | Train Loss: 0.5898041 Vali Loss: 0.3065306 Test Loss: 0.4366767
Validation loss decreased (inf --> 0.306531).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7210809
	speed: 0.9042s/iter; left time: 8487.9037s
	iters: 200, epoch: 2 | loss: 0.6672351
	speed: 0.1428s/iter; left time: 1325.9601s
	iters: 300, epoch: 2 | loss: 0.7262253
	speed: 0.1429s/iter; left time: 1312.6659s
	iters: 400, epoch: 2 | loss: 0.4353360
	speed: 0.1430s/iter; left time: 1299.6470s
	iters: 500, epoch: 2 | loss: 0.6114734
	speed: 0.1431s/iter; left time: 1285.8909s
	iters: 600, epoch: 2 | loss: 1.1285878
	speed: 0.1431s/iter; left time: 1271.3751s
	iters: 700, epoch: 2 | loss: 0.8260810
	speed: 0.1430s/iter; left time: 1256.5802s
	iters: 800, epoch: 2 | loss: 0.4239109
	speed: 0.1428s/iter; left time: 1240.8784s
	iters: 900, epoch: 2 | loss: 0.3228065
	speed: 0.1429s/iter; left time: 1227.4849s
	iters: 1000, epoch: 2 | loss: 0.5397378
	speed: 0.1429s/iter; left time: 1212.7225s
Epoch: 2 cost time: 150.66597986221313
Epoch: 2, Steps: 1054 | Train Loss: 0.5615637 Vali Loss: 0.3354408 Test Loss: 0.4816316
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7055882
	speed: 0.9021s/iter; left time: 7516.7865s
	iters: 200, epoch: 3 | loss: 0.9240248
	speed: 0.1428s/iter; left time: 1175.7526s
	iters: 300, epoch: 3 | loss: 0.6051578
	speed: 0.1428s/iter; left time: 1161.7570s
	iters: 400, epoch: 3 | loss: 0.5076298
	speed: 0.1428s/iter; left time: 1146.7283s
	iters: 500, epoch: 3 | loss: 0.7379344
	speed: 0.1427s/iter; left time: 1132.1596s
	iters: 600, epoch: 3 | loss: 0.4371894
	speed: 0.1428s/iter; left time: 1118.3242s
	iters: 700, epoch: 3 | loss: 0.5872266
	speed: 0.1429s/iter; left time: 1105.2446s
	iters: 800, epoch: 3 | loss: 0.9451669
	speed: 0.1428s/iter; left time: 1090.1715s
	iters: 900, epoch: 3 | loss: 0.3882628
	speed: 0.1430s/iter; left time: 1077.5658s
	iters: 1000, epoch: 3 | loss: 0.4342586
	speed: 0.1429s/iter; left time: 1062.3615s
Epoch: 3 cost time: 150.54960012435913
Epoch: 3, Steps: 1054 | Train Loss: 0.5125747 Vali Loss: 0.3708335 Test Loss: 0.5552842
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3291776
	speed: 0.9007s/iter; left time: 6556.3573s
	iters: 200, epoch: 4 | loss: 0.7699003
	speed: 0.1428s/iter; left time: 1025.2808s
	iters: 300, epoch: 4 | loss: 0.5789317
	speed: 0.1429s/iter; left time: 1011.5105s
	iters: 400, epoch: 4 | loss: 0.4784293
	speed: 0.1429s/iter; left time: 997.2232s
	iters: 500, epoch: 4 | loss: 0.3146729
	speed: 0.1430s/iter; left time: 983.4353s
	iters: 600, epoch: 4 | loss: 0.4274668
	speed: 0.1429s/iter; left time: 968.9428s
	iters: 700, epoch: 4 | loss: 0.2965906
	speed: 0.1430s/iter; left time: 955.0089s
	iters: 800, epoch: 4 | loss: 0.3209078
	speed: 0.1430s/iter; left time: 940.8336s
	iters: 900, epoch: 4 | loss: 0.5673442
	speed: 0.1430s/iter; left time: 926.2656s
	iters: 1000, epoch: 4 | loss: 0.5808001
	speed: 0.1428s/iter; left time: 911.0989s
Epoch: 4 cost time: 150.60759258270264
Epoch: 4, Steps: 1054 | Train Loss: 0.4911415 Vali Loss: 0.3733285 Test Loss: 0.5666280
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_Autoformer_ETTm2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed3293<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.4363429844379425, mae:0.42794811725616455
