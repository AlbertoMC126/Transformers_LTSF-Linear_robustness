Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, features='M', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Autoformer', model_id='ETTm2_720', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=3, pred_len=720, root_path='./dataset/', seed=3144, seq_len=96, target='OT', test_flop=False, train_epochs=10, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_Autoformer_ETTm2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed3144>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.3509345
	speed: 0.1772s/iter; left time: 1850.3300s
	iters: 200, epoch: 1 | loss: 0.7966539
	speed: 0.1428s/iter; left time: 1476.1958s
	iters: 300, epoch: 1 | loss: 0.5252454
	speed: 0.1431s/iter; left time: 1465.0801s
	iters: 400, epoch: 1 | loss: 0.3423548
	speed: 0.1430s/iter; left time: 1449.9752s
	iters: 500, epoch: 1 | loss: 0.4675231
	speed: 0.1431s/iter; left time: 1437.1838s
	iters: 600, epoch: 1 | loss: 0.4605102
	speed: 0.1429s/iter; left time: 1420.2525s
	iters: 700, epoch: 1 | loss: 0.3203956
	speed: 0.1429s/iter; left time: 1405.8896s
	iters: 800, epoch: 1 | loss: 1.2276804
	speed: 0.1429s/iter; left time: 1391.6563s
	iters: 900, epoch: 1 | loss: 0.7322769
	speed: 0.1429s/iter; left time: 1377.3945s
	iters: 1000, epoch: 1 | loss: 0.4778979
	speed: 0.1426s/iter; left time: 1360.6981s
Epoch: 1 cost time: 154.09871244430542
Epoch: 1, Steps: 1054 | Train Loss: 0.5921288 Vali Loss: 0.2904047 Test Loss: 0.4234870
Validation loss decreased (inf --> 0.290405).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3987074
	speed: 0.9029s/iter; left time: 8475.3687s
	iters: 200, epoch: 2 | loss: 0.3956687
	speed: 0.1430s/iter; left time: 1327.9245s
	iters: 300, epoch: 2 | loss: 0.3366389
	speed: 0.1426s/iter; left time: 1310.2514s
	iters: 400, epoch: 2 | loss: 0.4064354
	speed: 0.1427s/iter; left time: 1296.7268s
	iters: 500, epoch: 2 | loss: 0.7703592
	speed: 0.1431s/iter; left time: 1285.6228s
	iters: 600, epoch: 2 | loss: 0.6427826
	speed: 0.1431s/iter; left time: 1272.0647s
	iters: 700, epoch: 2 | loss: 0.4086817
	speed: 0.1430s/iter; left time: 1256.1479s
	iters: 800, epoch: 2 | loss: 0.9675046
	speed: 0.1429s/iter; left time: 1241.3232s
	iters: 900, epoch: 2 | loss: 0.3723496
	speed: 0.1429s/iter; left time: 1227.0244s
	iters: 1000, epoch: 2 | loss: 0.5666539
	speed: 0.1429s/iter; left time: 1212.7767s
Epoch: 2 cost time: 150.58272075653076
Epoch: 2, Steps: 1054 | Train Loss: 0.5794419 Vali Loss: 0.3254613 Test Loss: 0.4799924
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9067199
	speed: 0.9022s/iter; left time: 7518.1156s
	iters: 200, epoch: 3 | loss: 0.3205381
	speed: 0.1428s/iter; left time: 1176.0470s
	iters: 300, epoch: 3 | loss: 0.3309461
	speed: 0.1428s/iter; left time: 1161.7296s
	iters: 400, epoch: 3 | loss: 0.8014669
	speed: 0.1429s/iter; left time: 1147.5269s
	iters: 500, epoch: 3 | loss: 0.2907448
	speed: 0.1431s/iter; left time: 1135.3666s
	iters: 600, epoch: 3 | loss: 0.4373861
	speed: 0.1430s/iter; left time: 1120.0576s
	iters: 700, epoch: 3 | loss: 0.3943350
	speed: 0.1430s/iter; left time: 1106.0077s
	iters: 800, epoch: 3 | loss: 0.3867418
	speed: 0.1429s/iter; left time: 1091.0088s
	iters: 900, epoch: 3 | loss: 0.8060442
	speed: 0.1428s/iter; left time: 1075.6941s
	iters: 1000, epoch: 3 | loss: 0.3506281
	speed: 0.1429s/iter; left time: 1061.8511s
Epoch: 3 cost time: 150.61783576011658
Epoch: 3, Steps: 1054 | Train Loss: 0.5610977 Vali Loss: 0.3238886 Test Loss: 0.5173205
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6859400
	speed: 0.9002s/iter; left time: 6552.7521s
	iters: 200, epoch: 4 | loss: 0.3066368
	speed: 0.1427s/iter; left time: 1024.3809s
	iters: 300, epoch: 4 | loss: 0.4283286
	speed: 0.1428s/iter; left time: 1010.9695s
	iters: 400, epoch: 4 | loss: 0.6634400
	speed: 0.1429s/iter; left time: 997.1323s
	iters: 500, epoch: 4 | loss: 0.7798714
	speed: 0.1430s/iter; left time: 983.4601s
	iters: 600, epoch: 4 | loss: 0.5160608
	speed: 0.1430s/iter; left time: 969.1393s
	iters: 700, epoch: 4 | loss: 0.5119578
	speed: 0.1431s/iter; left time: 955.4843s
	iters: 800, epoch: 4 | loss: 0.5697892
	speed: 0.1432s/iter; left time: 941.9621s
	iters: 900, epoch: 4 | loss: 0.4756961
	speed: 0.1430s/iter; left time: 926.6272s
	iters: 1000, epoch: 4 | loss: 0.5350303
	speed: 0.1429s/iter; left time: 911.3074s
Epoch: 4 cost time: 150.63150548934937
Epoch: 4, Steps: 1054 | Train Loss: 0.5484624 Vali Loss: 0.3394727 Test Loss: 0.5362286
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_Autoformer_ETTm2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed3144<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.4231396019458771, mae:0.4180135428905487
