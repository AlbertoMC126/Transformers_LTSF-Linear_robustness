Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=8, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='exchange_rate.csv', dec_in=8, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=8, factor=3, features='M', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Transformer', model_id='exchange_336', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=3, pred_len=336, root_path='./dataset/', seed=15227, seq_len=96, target='OT', test_flop=False, train_epochs=10, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : exchange_336_Transformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed15227>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4880
val 425
test 1182
	iters: 100, epoch: 1 | loss: 0.1239045
	speed: 0.0745s/iter; left time: 105.7961s
Epoch: 1 cost time: 9.734441757202148
Epoch: 1, Steps: 152 | Train Loss: 0.1936637 Vali Loss: 2.2826257 Test Loss: 1.8446641
Validation loss decreased (inf --> 2.282626).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0570215
	speed: 0.0757s/iter; left time: 96.0448s
Epoch: 2 cost time: 6.622028827667236
Epoch: 2, Steps: 152 | Train Loss: 0.0686605 Vali Loss: 2.2742479 Test Loss: 1.5851059
Validation loss decreased (2.282626 --> 2.274248).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.0491666
	speed: 0.0759s/iter; left time: 84.7939s
Epoch: 3 cost time: 6.622382640838623
Epoch: 3, Steps: 152 | Train Loss: 0.0520262 Vali Loss: 2.2992442 Test Loss: 1.5425354
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.0482351
	speed: 0.0734s/iter; left time: 70.8605s
Epoch: 4 cost time: 6.624426364898682
Epoch: 4, Steps: 152 | Train Loss: 0.0468065 Vali Loss: 2.2419488 Test Loss: 1.4943882
Validation loss decreased (2.274248 --> 2.241949).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.0422411
	speed: 0.0753s/iter; left time: 61.2442s
Epoch: 5 cost time: 6.6407036781311035
Epoch: 5, Steps: 152 | Train Loss: 0.0441625 Vali Loss: 2.2150764 Test Loss: 1.4592026
Validation loss decreased (2.241949 --> 2.215076).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.0451394
	speed: 0.0760s/iter; left time: 50.2301s
Epoch: 6 cost time: 6.6504294872283936
Epoch: 6, Steps: 152 | Train Loss: 0.0428728 Vali Loss: 2.2360339 Test Loss: 1.4771656
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.0428426
	speed: 0.0737s/iter; left time: 37.5210s
Epoch: 7 cost time: 6.645648002624512
Epoch: 7, Steps: 152 | Train Loss: 0.0421543 Vali Loss: 2.2257924 Test Loss: 1.4590567
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.0414505
	speed: 0.0737s/iter; left time: 26.3243s
Epoch: 8 cost time: 6.641279458999634
Epoch: 8, Steps: 152 | Train Loss: 0.0418153 Vali Loss: 2.2067442 Test Loss: 1.4519588
Validation loss decreased (2.215076 --> 2.206744).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.0403207
	speed: 0.0766s/iter; left time: 15.7019s
Epoch: 9 cost time: 6.632467031478882
Epoch: 9, Steps: 152 | Train Loss: 0.0416133 Vali Loss: 2.2257752 Test Loss: 1.4600673
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.0397721
	speed: 0.0734s/iter; left time: 3.8886s
Epoch: 10 cost time: 6.615076780319214
Epoch: 10, Steps: 152 | Train Loss: 0.0414675 Vali Loss: 2.2110429 Test Loss: 1.4562016
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : exchange_336_Transformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed15227<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1182
mse:1.452481985092163, mae:0.9588459730148315
