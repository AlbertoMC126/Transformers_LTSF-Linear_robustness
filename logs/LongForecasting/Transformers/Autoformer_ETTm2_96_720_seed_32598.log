Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='ETTm2', data_path='ETTm2.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=7, factor=3, features='M', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Autoformer', model_id='ETTm2_720', moving_avg=25, n_heads=8, num_workers=0, output_attention=False, patience=3, pred_len=720, root_path='./dataset/', seed=32598, seq_len=96, target='OT', test_flop=False, train_epochs=10, train_only=False, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_Autoformer_ETTm2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed32598>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4179944
	speed: 0.1768s/iter; left time: 1845.5673s
	iters: 200, epoch: 1 | loss: 0.9162294
	speed: 0.1426s/iter; left time: 1475.0649s
	iters: 300, epoch: 1 | loss: 0.3517152
	speed: 0.1427s/iter; left time: 1461.7192s
	iters: 400, epoch: 1 | loss: 0.3673126
	speed: 0.1428s/iter; left time: 1448.2349s
	iters: 500, epoch: 1 | loss: 0.5368767
	speed: 0.1427s/iter; left time: 1432.8972s
	iters: 600, epoch: 1 | loss: 0.9924021
	speed: 0.1427s/iter; left time: 1418.6019s
	iters: 700, epoch: 1 | loss: 0.5011647
	speed: 0.1430s/iter; left time: 1406.9778s
	iters: 800, epoch: 1 | loss: 0.3772932
	speed: 0.1430s/iter; left time: 1392.5513s
	iters: 900, epoch: 1 | loss: 0.4603139
	speed: 0.1428s/iter; left time: 1377.0080s
	iters: 1000, epoch: 1 | loss: 0.4688043
	speed: 0.1428s/iter; left time: 1362.0317s
Epoch: 1 cost time: 153.97588968276978
Epoch: 1, Steps: 1054 | Train Loss: 0.5886095 Vali Loss: 0.3099771 Test Loss: 0.4332363
Validation loss decreased (inf --> 0.309977).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6423808
	speed: 0.9012s/iter; left time: 8459.8216s
	iters: 200, epoch: 2 | loss: 0.5263530
	speed: 0.1427s/iter; left time: 1325.3451s
	iters: 300, epoch: 2 | loss: 0.6757138
	speed: 0.1427s/iter; left time: 1311.2770s
	iters: 400, epoch: 2 | loss: 0.5421072
	speed: 0.1428s/iter; left time: 1297.3580s
	iters: 500, epoch: 2 | loss: 0.8730896
	speed: 0.1428s/iter; left time: 1283.5856s
	iters: 600, epoch: 2 | loss: 0.6390805
	speed: 0.1427s/iter; left time: 1267.8691s
	iters: 700, epoch: 2 | loss: 0.7852329
	speed: 0.1426s/iter; left time: 1253.2144s
	iters: 800, epoch: 2 | loss: 0.3564357
	speed: 0.1429s/iter; left time: 1241.4641s
	iters: 900, epoch: 2 | loss: 0.5595878
	speed: 0.1429s/iter; left time: 1227.0582s
	iters: 1000, epoch: 2 | loss: 0.5567619
	speed: 0.1427s/iter; left time: 1210.7667s
Epoch: 2 cost time: 150.4432303905487
Epoch: 2, Steps: 1054 | Train Loss: 0.5557798 Vali Loss: 0.4017873 Test Loss: 0.5144131
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3066747
	speed: 0.8968s/iter; left time: 7473.2952s
	iters: 200, epoch: 3 | loss: 0.7038319
	speed: 0.1428s/iter; left time: 1175.4866s
	iters: 300, epoch: 3 | loss: 0.9406607
	speed: 0.1427s/iter; left time: 1160.3926s
	iters: 400, epoch: 3 | loss: 0.3212994
	speed: 0.1427s/iter; left time: 1146.4836s
	iters: 500, epoch: 3 | loss: 0.5719875
	speed: 0.1428s/iter; left time: 1132.5462s
	iters: 600, epoch: 3 | loss: 0.5054328
	speed: 0.1428s/iter; left time: 1118.4933s
	iters: 700, epoch: 3 | loss: 0.6169212
	speed: 0.1427s/iter; left time: 1103.4919s
	iters: 800, epoch: 3 | loss: 0.5738108
	speed: 0.1428s/iter; left time: 1090.3510s
	iters: 900, epoch: 3 | loss: 0.5015358
	speed: 0.1429s/iter; left time: 1076.0955s
	iters: 1000, epoch: 3 | loss: 0.6633258
	speed: 0.1428s/iter; left time: 1061.8038s
Epoch: 3 cost time: 150.47857689857483
Epoch: 3, Steps: 1054 | Train Loss: 0.4907244 Vali Loss: 0.4894769 Test Loss: 0.6631458
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4286717
	speed: 0.8976s/iter; left time: 6533.3134s
	iters: 200, epoch: 4 | loss: 0.5290981
	speed: 0.1425s/iter; left time: 1023.3546s
	iters: 300, epoch: 4 | loss: 0.3995061
	speed: 0.1429s/iter; left time: 1011.5424s
	iters: 400, epoch: 4 | loss: 0.5445427
	speed: 0.1428s/iter; left time: 996.7095s
	iters: 500, epoch: 4 | loss: 0.3982230
	speed: 0.1428s/iter; left time: 982.4957s
	iters: 600, epoch: 4 | loss: 0.6350254
	speed: 0.1429s/iter; left time: 968.4976s
	iters: 700, epoch: 4 | loss: 0.3830995
	speed: 0.1429s/iter; left time: 954.2238s
	iters: 800, epoch: 4 | loss: 0.7393447
	speed: 0.1428s/iter; left time: 939.2453s
	iters: 900, epoch: 4 | loss: 0.7597882
	speed: 0.1429s/iter; left time: 925.8235s
	iters: 1000, epoch: 4 | loss: 0.5411717
	speed: 0.1429s/iter; left time: 911.5173s
Epoch: 4 cost time: 150.4849705696106
Epoch: 4, Steps: 1054 | Train Loss: 0.4602389 Vali Loss: 0.5359583 Test Loss: 0.7164714
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_720_Autoformer_ETTm2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0_seed32598<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.43278083205223083, mae:0.4285769462585449
